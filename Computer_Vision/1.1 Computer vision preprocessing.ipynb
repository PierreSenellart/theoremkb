{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-elements",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install pdf2image #installing the necessary package\n",
    "!brew install poppler #turn this on for macs\n",
    "!pip3 install cmake\n",
    "!pip3 install python-poppler\n",
    "!pip3 install bs4 lxml #this is required for xml parsing\n",
    "!pip3 install natsort #for sorting files\n",
    "!pip3 install opencv-python #open cv for converting images\n",
    "!pip install pytesseract #installing pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf='' #this is the pdf with links\n",
    "xml_main='' #this contains the page locations\n",
    "annot_xml='' #this contains annotations width\n",
    "\n",
    "out_pdf=\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def remove_pdf_links(inp_pdf,out_pdf=None):\n",
    "    \n",
    "    \n",
    "    if(out_pdf==None):\n",
    "        out_pdf=inp_pdf.rsplit(\".\",1)\n",
    "        out_pdf_temp=out_pdf[0]+\"_stripped_temp.\"+out_pdf[1]\n",
    "        out_pdf=out_pdf[0]+\"_stripped.\"+out_pdf[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #code for conversion\n",
    "    first_cmd=\" \".join([\"pdftk\", \"{}\".format(inp_pdf),\"output\", \"{}\".format(out_pdf_temp), \"uncompress\"])\n",
    "    second_cmd=\"LC_ALL=C sed -n '/^\\/Annots/!p' {} > {}\".format(out_pdf_temp,inp_pdf)\n",
    "    \n",
    "    #call first command \n",
    "    \n",
    "    subprocess.call(first_cmd,shell=True)\n",
    "    \n",
    "    #call second command\n",
    "    ret=subprocess.call(second_cmd,shell=True)\n",
    "    \n",
    "    os.remove(out_pdf_temp)\n",
    "\n",
    "remove_pdf_links(sample_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from math import floor\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def pdf2_image(pdf_path,xml_main):\n",
    "    \n",
    "    #get the resolution of each pdf page from xml\n",
    "    content = []\n",
    "    # Read the XML file\n",
    "    with open(xml_main, \"r\") as file:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # Combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        #print(bs_content)\n",
    "        page_info=bs_content.find_all(\"Page\")\n",
    "        resolution=[]\n",
    "        for page in page_info:\n",
    "            height=floor(float(page.get(\"HEIGHT\")))\n",
    "            width=floor(float(page.get(\"WIDTH\")))\n",
    "            resolution.append((width,height))\n",
    "    file.close()\n",
    "    \n",
    "    #print(resolution)\n",
    "        \n",
    "    #convert the pdf to image using the coordinates from the xml_file\n",
    "    all_pages=[]\n",
    "    \n",
    "    ff=1\n",
    "    lf=len(resolution)\n",
    "    image = convert_from_path(pdf_path,first_page=ff,last_page=lf,use_pdftocairo=True,fmt=\"png\")\n",
    "    \n",
    "    skip=False #default value\n",
    "    \n",
    "    if(len(resolution)!=len(image)):\n",
    "        skip=True\n",
    "        resolution.pop(0)\n",
    "    \n",
    "        \n",
    "    #print(all_pages)\n",
    "        \n",
    "    #make a new directory in pdf folder\n",
    "    \n",
    "    return image,resolution,skip\n",
    "\n",
    "\n",
    "\n",
    "#contains the list of the images\n",
    "all_images,resolution,skip=pdf2_image(sample_pdf,xml_main)\n",
    "\n",
    "\n",
    "print(len(all_images),len(resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's view the image and save\n",
    "def get_magnifications(sample_pdf,resolution,all_images):\n",
    "    \n",
    "    try:\n",
    "        path=sample_pdf.rsplit(\"/\",1)[0]+\"/images\"\n",
    "        #print(path)\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        print(\"path already exists !!!!\")\n",
    "\n",
    "    #print(path)     \n",
    "    magnifications=[]\n",
    "    \n",
    "    i=0\n",
    "    for image,res in zip(all_images,resolution):\n",
    "        #print (image.format, image.size, image.mode)\n",
    "        new_width=image.size[0]\n",
    "        original_width=res[0]\n",
    "        new_height=image.size[1]\n",
    "        original_height=res[1]\n",
    "        mag_width=new_width/original_width\n",
    "        mag_height=new_height/original_height\n",
    "        magnifications.append([mag_width,mag_height])\n",
    "        #image.show()\n",
    "        image.save(path+\"/\"+\"image_\"+str(i+1)+'.png', 'PNG')\n",
    "        i+=1\n",
    "        \n",
    "    return magnifications\n",
    "\n",
    "magnifications=get_magnifications(sample_pdf,resolution,all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(magnifications)\n",
    "print(len(magnifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-subject",
   "metadata": {},
   "source": [
    "# given the annot.xml file locate the coordinates of the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def get_all_boxes(xml,magnifications,skip=False):\n",
    "    # Read the XML file\n",
    "    with open(xml, \"r\") as file:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # Combine the lines in the list into a string\n",
    "        #print(content)\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        \n",
    "        \n",
    "        page_info=bs_content.find_all(\"ANNOTATION\")\n",
    "        quads=bs_content.find_all(\"QUADRILATERAL\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        extractions=[]\n",
    "        #filter magnifications for certain pages\n",
    "        \n",
    "        \n",
    "        for action_,quad in zip(page_info,quads):\n",
    "            if(action_.DEST.string!=None): #valid box\n",
    "                page_no=int(action_.get(\"pagenum\")) #basically the page_num\n",
    "                \n",
    "                class_=action_.DEST.string #the type of the box\n",
    "                \n",
    "                #if the type of the box is some link then skip it dont extract it\n",
    "                if(\"@\" in class_):\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                coord=[[floor(float(x.get(\"HPOS\"))),floor(float(x.get(\"VPOS\")))] for x in quad] #the coordinates\n",
    "                if(skip):\n",
    "                    extractions.append([page_no-1,coord,class_]) \n",
    "                else:\n",
    "                    extractions.append([page_no,coord,class_]) \n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    #print(extractions)\n",
    "    #we need to filter magnifications for each page\n",
    "    for i in range(len(magnifications)):\n",
    "        #print(i)\n",
    "        for k,elements in enumerate(extractions):\n",
    "            #print(elements)\n",
    "            #print(elements)\n",
    "            if(elements[0]==i+1):\n",
    "                \n",
    "                #print(extractions[k][1])\n",
    "                \n",
    "                #change the two coordinates\n",
    "                for d in range(len(elements[1])): #for all coordinates change their pix values\n",
    "                    extractions[k][1][d][0]=floor(extractions[k][1][d][0]*magnifications[i][0])\n",
    "                    extractions[k][1][d][1]=floor(extractions[k][1][d][1]*magnifications[i][1])\n",
    "                \n",
    "    return extractions\n",
    "\n",
    "boxes=get_all_boxes(annot_xml,magnifications,skip)\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boxes[:5]) #an example of boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-camera",
   "metadata": {},
   "source": [
    "# extract the information on the images from the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort \n",
    "from PIL import Image\n",
    "\n",
    "def draw_rectangles(images_dir,boxes,show_images=False):\n",
    "    \"\"\"takes the images from the image path reads them and plots a rectange on them\n",
    "    also return the patches for each detected page  \n",
    "    \"\"\"\n",
    "    #print(images_dir)\n",
    "    pages=[]\n",
    "    box=[]\n",
    "    names=[]\n",
    "    \n",
    "    boxes_per_page={}\n",
    "    for info in boxes:\n",
    "        page=info[0]\n",
    "        rect=info[1]\n",
    "        if(page not in boxes_per_page):\n",
    "            boxes_per_page[page]=[rect]\n",
    "        else:\n",
    "            boxes_per_page[page].append(rect)\n",
    "            \n",
    "    #print(boxes_per_page)\n",
    "    patches={}\n",
    "    \n",
    "    for k,v in boxes_per_page.items():\n",
    "        image_path=images_dir+f\"/image_{k}.png\"\n",
    "        image=cv2.imread(image_path)\n",
    "        \n",
    "        \n",
    "        #v=[[1,2,3,4],[1,2,3,4]]\n",
    "        cropped_images=[]\n",
    "        \n",
    "        #crop the images\n",
    "        for boxes in v:\n",
    "            #print(boxes)\n",
    "            top_left=boxes[1] #x1,y1\n",
    "            bottom_right=boxes[2] #x2,y2\n",
    "            \n",
    "            \n",
    "            #cropping images\n",
    "            cropped = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "             \n",
    "\n",
    "            cropped_images.append(cropped)\n",
    "                \n",
    "            \n",
    "        patches[k]= cropped_images\n",
    "        \n",
    "        if(show_images): #shows all boxes including filtered boxes\n",
    "            for boxes in v:\n",
    "                (x1,y1),(x2,y2)=boxes[1],boxes[2]\n",
    "                image=cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "                cv2.imshow(\"test\",image)\n",
    "                cv2.waitKey()\n",
    "            \n",
    "    return patches,boxes_per_page\n",
    "            \n",
    "        \n",
    "path=sample_pdf.rsplit(\"/\",1)[0]+\"/images\"  \n",
    "patches,boxes_per_page=draw_rectangles(path,boxes,show_images=True) #patches only contain the protions of the \n",
    "print(boxes_per_page.keys())\n",
    "print(patches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images before deletion\n",
    "a=os.listdir(path)\n",
    "a.sort()\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-spotlight",
   "metadata": {},
   "source": [
    "print(len(patches))\n",
    "patch_len=0\n",
    "for patch in patches.values():\n",
    "    patch_len+=len(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_irrelevant_images(patches,all_images,path):\n",
    "    \n",
    "    for i in range(1,len(all_images)): #from image 1 to last\n",
    "        if(i not in patches.keys()):\n",
    "            os.remove(path+\"/\"+\"image_\"+str(i)+'.png')\n",
    "            \n",
    "delete_irrelevant_images(patches,all_images,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90047b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xml_main,len(magnifications),len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe87826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path) #you can check this path to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=os.listdir(path)\n",
    "a.sort()\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-millennium",
   "metadata": {},
   "source": [
    "# How can we filter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-gathering",
   "metadata": {},
   "source": [
    "# The pytesseract way -(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(patches)\n",
    "\n",
    "#check pytesseract for each image\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "def image_to_text(image,show_image=False,show_text=False):\n",
    "\n",
    "    # By default OpenCV stores images in BGR format and since pytesseract assumes RGB format,\n",
    "    # we need to convert from BGR to RGB format/mode:\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    ocr_chars=image_to_string(img_rgb)\n",
    "\n",
    "    if(show_text):\n",
    "        print(\"tesseract values >>>>>>>\")\n",
    "        print(\"this is my length: \",len(ocr_chars))\n",
    "        print(ocr_chars)\n",
    "        print(\"tesseract values <<<<<<<\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    if(show_image):\n",
    "        cv2.imshow(\"detection :\",numpy_arr_of_image)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "            \n",
    "    return ocr_chars    \n",
    "            \n",
    "        \n",
    "    #print(pytesseract.image_to_string(Image.open(patch)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-trouble",
   "metadata": {},
   "source": [
    "all_text=[]\n",
    "for patch in patches.values():\n",
    "    for numpy_arr_of_image in tqdm(patch):\n",
    "        text=image_to_text(numpy_arr_of_image,show_image=False,show_text=False)\n",
    "        all_text.append(text)\n",
    "        \n",
    "print(\"these are my all texts : \",len(all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-commissioner",
   "metadata": {},
   "source": [
    "# The contour way of determining the patches - method (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_of_image(image,show_text=False,show_image=False):\n",
    "               \n",
    "    #we need to convert the image into gray scale to get contour values\n",
    "    # Grayscale\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    gray = cv2.cvtColor(rgb_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find Canny edges\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "    #print(\"contours: >>>>>>>\")\n",
    "    contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if(show_text):\n",
    "        print(\"Number of Contours found = \" + str(len(contours)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(show_image):\n",
    "        # Draw all contours\n",
    "        # Use '-1' as the 3rd parameter to draw all\n",
    "        cv2.drawContours(image, contours, -1, (0,255,0), 1)\n",
    "        cv2.imshow('Contours:'+str(len(contours)), image)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "                           \n",
    "    return len(contours)\n",
    "    #print(pytesseract.image_to_string(Image.open(patch)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-mistress",
   "metadata": {},
   "source": [
    "all_contours=[]\n",
    "for patch in patches.values():\n",
    "    for numpy_arr_of_image in patch:\n",
    "        contours_count=get_contours_of_image(numpy_arr_of_image,show_text=False)\n",
    "        all_contours.append(contours_count)\n",
    "        #print(\"countours count: \",str(contours_count))\n",
    "        \n",
    "print(\"these are my all contours : \",len(all_contours))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-florence",
   "metadata": {},
   "source": [
    "# filter elements based on their area method -(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_area(image,show_text=False):\n",
    "    width=image.shape[0]\n",
    "    height=image.shape[1]\n",
    "    area=(width*height)/100 #in pixel square\n",
    "    \n",
    "    if(show_text):\n",
    "        print(area)\n",
    "        \n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-constitutional",
   "metadata": {},
   "source": [
    "all_areas=[]\n",
    "for patch in patches.values():\n",
    "    for numpy_arr_of_image in patch:\n",
    "        area_image=image_to_area(numpy_arr_of_image,show_text=False)\n",
    "        all_areas.append(area_image)\n",
    "print(\"these are my all areas : \",len(all_areas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-murder",
   "metadata": {},
   "source": [
    "# we need to get the text from xml file method -(d)\n",
    "\n",
    "1. for all boxes in the boxes detected \n",
    "2. for all characters in the pdf- specifically that page\n",
    "3. we need to do a comparison if the coordinates they lie on or under the theorem box\n",
    "4. we need to concatenate each of the characters in the box for the given theorem box\n",
    "5. we also take care of the spaces in between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def box_to_text_using_xml(xml_main, magnifications,boxes,show_text=False,skip=False):\n",
    "    \"\"\"take a box coodinates xml file to check and adjusted magnifications\n",
    "    and return what characters are inside the box basically text version\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(xml_main,\"r\") as file:\n",
    "        content=file.readlines()\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        #print(bs_content)\n",
    "        text_blocks={}\n",
    "        page_info=bs_content.find_all(\"Page\")\n",
    "        \n",
    "        if(skip):\n",
    "            page_info.pop(0)\n",
    "        \n",
    "        \n",
    "        for i,page in enumerate(page_info): #traverse through all pages\n",
    "            \n",
    "            \n",
    "                \n",
    "            page_text=page.find_all(\"TextLine\")\n",
    "            text=[]\n",
    "            for text_bl in page_text:\n",
    "    \n",
    "                for element in text_bl:\n",
    "                    if(str(element).startswith(\"<String\")): #its a string \n",
    "                        try:\n",
    "                            content=element.get(\"CONTENT\")\n",
    "                            #print(content)\n",
    "                            h_pos=floor(float(element.get(\"HPOS\"))*magnifications[i][0])\n",
    "                            v_pos=floor(float(element.get(\"VPOS\"))*magnifications[i][1])\n",
    "                            #we can also extract the font \n",
    "\n",
    "                            text.append([content,h_pos,v_pos])\n",
    "                        except:\n",
    "                            print(element)\n",
    "                            print(i)\n",
    "                            print(magnifications[i][0])\n",
    "                            print(content)\n",
    "                        \n",
    "                        \n",
    "                    if(str(element).startswith(\"<SP\")):\n",
    "                        val=text.pop()\n",
    "                        val[0]+=\" \"\n",
    "                        text.append(val)\n",
    "                        \n",
    "                #print(text)\n",
    "            \n",
    "            text_blocks[i+1]=text\n",
    "    \n",
    "        file.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "    box_text={}\n",
    "    string_cats=[]\n",
    "    for box in boxes: #basically the big box\n",
    "        all_chars_on_page=text_blocks[box[0]] #small boxes\n",
    "\n",
    "        #coordinates of the big box\n",
    "        top_left_bb= copy.deepcopy(box[1][1])\n",
    "        bot_right_bb=copy.deepcopy(box[1][2])\n",
    "\n",
    "\n",
    "        #print(all_chars_on_page)\n",
    "        string_cat=\"\"\n",
    "        \n",
    "        for chars in all_chars_on_page:\n",
    "            if(top_left_bb[0]<=chars[1]<=bot_right_bb[0] and top_left_bb[1]<=chars[2]<=bot_right_bb[1]):\n",
    "                string_cat+=chars[0]\n",
    "                    \n",
    "        string_cats.append((box[0],string_cat))\n",
    "\n",
    "    for element in string_cats:\n",
    "        if(element[0] not in box_text):\n",
    "            box_text[element[0]]=[element[1]]\n",
    "        else:\n",
    "            box_text[element[0]].append(element[1])\n",
    "            \n",
    "    return box_text\n",
    "    \n",
    "    \n",
    "boxes_text=box_to_text_using_xml(xml_main,magnifications,boxes,show_text=False,skip=True)\n",
    "\n",
    "print(len(boxes_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xml_main,len(magnifications),len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(boxes_text[3])) #21 text found on page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group each of the filtering technique together\n",
    "def filter_thresholds(patches,boxes_text,boxes,show_text=False,show_image=False):\n",
    "    #cleaning the mess\n",
    "    area_th=2 #small blocks have low area\n",
    "    contour_th=8 #plain horizontal lines have low contours\n",
    "    text_th_ocr=2 #page number boxes have have low text\n",
    "    text_th_xml=3\n",
    "\n",
    "    thresholds=[text_th_ocr,contour_th,area_th,text_th_xml]\n",
    "    \n",
    "    box_map_cc=[]\n",
    "    selection={}\n",
    "    for page_info in patches.keys():\n",
    "\n",
    "        verdicts=[]\n",
    "\n",
    "        for image,text_xml in zip(patches[page_info],boxes_text[page_info]):\n",
    "\n",
    "            area=image_to_area(image,show_text=False)\n",
    "            contours_count=get_contours_of_image(image,show_text=False)\n",
    "            #text_ocr=image_to_text(numpy_arr_of_image,show_image=False,show_text=False)\n",
    "\n",
    "            if(show_text):\n",
    "                print(\"image area: \",area)\n",
    "                print(\"contours count: \",contours_count)\n",
    "                #print(\"text using ocr: and length\",(text_ocr,len(text_ocr)))\n",
    "                print(\"text using xml: and length\",(text_xml,len(text_xml)))\n",
    "                print(\"=======\")\n",
    "\n",
    "            if(show_image):\n",
    "                name=\"area {}. contours {}. text {}.\".format(area,contours_count,text_xml)\n",
    "                cv2.imshow(\"name\",image)\n",
    "                cv2.waitKey()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            small_area= area<area_th\n",
    "            small_contour_count= contours_count<contour_th\n",
    "\n",
    "            #less_text_ocr= len(text_ocr)<text_th_ocr #using tesseract ocr\n",
    "            less_text_xml=len(text_xml)<text_th_xml\n",
    "\n",
    "            less_text=less_text_xml\n",
    "\n",
    "            verdict=not(small_area or small_contour_count or less_text)\n",
    "            verdicts.append(verdict)\n",
    "            box_map_cc.append(verdict)\n",
    "            \n",
    "\n",
    "        selection[page_info]=verdicts\n",
    "\n",
    "\n",
    "    from itertools import compress\n",
    "\n",
    "    selection_=copy.deepcopy(selection)\n",
    "    \n",
    "    \n",
    "    for k,sels,box in zip(selection_.copy(),selection_.values(),boxes_text.values()):\n",
    "        new_images=list(compress(box, sels))\n",
    "\n",
    "        if(len(new_images)==0):\n",
    "            del selection[k]\n",
    "        else:\n",
    "            selection[k]=new_images\n",
    "            \n",
    "\n",
    "    #this is where we will start to filter each of the images\n",
    "    box_map_cc=list(compress(boxes, box_map_cc))\n",
    "    \n",
    "    return selection ,box_map_cc     \n",
    "\n",
    "\n",
    "\n",
    "selected,box_cc=filter_thresholds(patches,boxes_text,boxes,show_text=False,show_image=False)\n",
    "\n",
    "new_patches,boxes_per_page=draw_rectangles(path,box_cc,show_images=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-martial",
   "metadata": {},
   "source": [
    "area_th=2 #small blocks have low area\n",
    "contour_th=2 #plain horizontal lines have low conoturs\n",
    "text_th_ocr=2 #page number boxes have have low text\n",
    "text_th_xml=3\n",
    "\n",
    "thresholds=[text_th_ocr,contour_th,area_th,text_th_xml]\n",
    "selected=filter_thresholds(thresholds,patches,boxes_text,show_text=True,show_image=False)\n",
    "new_patches,boxes_per_page=draw_rectangles(path,selected,show_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-devil",
   "metadata": {},
   "source": [
    "#in page 17 we can see that there are some objects that can be seen \n",
    "\n",
    "for patch in patches[17]:\n",
    "    #show just boxes \n",
    "    cv2.imshow(\"name\",patch)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    area=image_to_area(patch,show_text=False)\n",
    "    contours_count=get_contours_of_image(patch,show_text=False)\n",
    "    text=len(image_to_text(patch,show_image=False,show_text=False))\n",
    "\n",
    "    print(\"image area: \",area)\n",
    "    print(\"contours count: \",contours_count)\n",
    "    print(\"text: \",text)\n",
    "    print(\"=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original categories #these are the seven categories that are orignally intended for\n",
    "def get_original_labels():\n",
    "    \"\"\"basically assigning labesls\"\"\"\n",
    "    categories=[\"assumption\",\"claim\",\"conjecture\",\"corollary\",\"definition\",\"lemma\",\"proof\",\"proposition\",\n",
    "                \"remark\", \"theorem\"]\n",
    "\n",
    "    category_map={}\n",
    "\n",
    "    for i,element in enumerate(categories):\n",
    "        category_map[element]=i\n",
    "\n",
    "    return category_map\n",
    "\n",
    "category_map=get_original_labels()\n",
    "\n",
    "#category map is a look up table \n",
    "print(category_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the data from the list and segment them according to the class\n",
    "def make_lookups(selected,category_map,binary=True):\n",
    "    look_up={} #this is the orgnal_lookup table matching page vs each subcategory\n",
    "    \n",
    "    for block in tqdm(selected):\n",
    "        page_num=block[0]\n",
    "        rectangle_coords=block[1]\n",
    "        tag=\"\".join(block[2].split(\":\")[1:])\n",
    "        tag=tag.split(\".\")[0]\n",
    "        if tag not in look_up: #if tag not in look_up add that tag\n",
    "            look_up[tag]=[[page_num,rectangle_coords]]\n",
    "        else:\n",
    "            look_up[tag].append([page_num,rectangle_coords]) #else append on the same tag\n",
    "    \n",
    "    #print(look_up.keys())\n",
    "    \n",
    "    for element in copy.deepcopy(look_up).keys():\n",
    "        if (element not in category_map):\n",
    "            del look_up[element]\n",
    "    #print(set(look_up.keys()),len(set(look_up.keys())))\n",
    "\n",
    "    #get_name(\"defination1\") #this becomes defination\n",
    "\n",
    "\n",
    "    new_look_up={}\n",
    "\n",
    "    for k,v in look_up.items():\n",
    "        name=k\n",
    "        if(category_map[name] not in new_look_up):\n",
    "            new_look_up[category_map[name]]=look_up[k]\n",
    "        else:\n",
    "            for element in look_up[k]:\n",
    "                new_look_up[category_map[name]].append(element)\n",
    "\n",
    "    \n",
    "    #print(new_look_up)\n",
    "    #new look ups\n",
    "    ll=copy.deepcopy(new_look_up)\n",
    "\n",
    "    #put everything that is not proof in theorem \n",
    "    if(binary==True):\n",
    "        for k,v in ll.items():\n",
    "            if(k!=category_map[\"theorem\"] and k!= category_map[\"proof\"]):\n",
    "\n",
    "                for element in new_look_up[k]:\n",
    "                    new_look_up[category_map[\"theorem\"]].append(element)\n",
    "\n",
    "                #delete\n",
    "                del new_look_up[k]\n",
    "\n",
    "    \n",
    "    return new_look_up\n",
    "\n",
    "\n",
    "\n",
    "def convert_yolo(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return x,y,w,h\n",
    "\n",
    "def boxes_to_yolo(new_look_up,path):\n",
    "    for k,v in new_look_up.items():\n",
    "        for i,box in enumerate(v):\n",
    "            image_no=box[0]\n",
    "\n",
    "            #read through this image path\n",
    "            image=path+\"/\"+\"image_\"+str(image_no)+'.png'\n",
    "            im=Image.open(image) \n",
    "\n",
    "            w= int(im.size[0]) #the x axis of the image\n",
    "            h= int(im.size[1]) #the y axis of the image\n",
    "\n",
    "            xmin=box[1][1][0]\n",
    "            ymin=box[1][1][1]\n",
    "            xmax=box[1][2][0]\n",
    "            ymax=box[1][2][1]\n",
    "\n",
    "            #print(xmin, xmax, ymin, ymax)\n",
    "\n",
    "            b = (xmin, xmax, ymin, ymax)\n",
    "\n",
    "            x,y,w,h = convert_yolo((w,h), b)\n",
    "\n",
    "\n",
    "            new_look_up[k][i][1]=[x,y,w,h]\n",
    "            \n",
    "    return new_look_up\n",
    "\n",
    "new_look_up=make_lookups(box_cc,category_map,binary=True)\n",
    "new_look_up=boxes_to_yolo(new_look_up,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-violence",
   "metadata": {},
   "source": [
    "from pdf2image import convert_from_path\n",
    "from math import floor\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "#wrapping everything together\n",
    "sample_pdf=\"/Users/mv96/Desktop/dummy/pdf/toto/toto.pdf\" #this is the pdf with links\n",
    "xml_main=\"/Users/mv96/Desktop/dummy/xml/toto/toto.xml\" #this contains the page locations\n",
    "annot_xml=\"/Users/mv96/Desktop/dummy/xml/toto/toto_annot.xml\" #this contains annotations width\n",
    "\n",
    "#converts the pdf into images\n",
    "all_images,resolution=pdf2_image(sample_pdf,xml_main)\n",
    "\n",
    "#get magnifications\n",
    "magnifications=get_magnifications(sample_pdf,resolution)\n",
    "\n",
    "#get all boxes from annot xml\n",
    "boxes=get_all_boxes(annot_xml,magnifications)\n",
    "\n",
    "#get the sample pdf path \n",
    "path=sample_pdf.rsplit(\"/\",1)[0]+\"/images\"\n",
    "\n",
    "\n",
    "#we have seen 4 methods to filter these patches\n",
    "\n",
    "#1 works on the pytesseract ocr way it takes time\n",
    "#2 works on detecting the contours in the image \n",
    "#3 works on the area based filtering of patches\n",
    "#4 works on text extraction by xml\n",
    "\n",
    "\n",
    "# but text extraction works on box coordinates not on patches\n",
    "boxes_text=box_to_text_using_xml(xml_main,magnifications,boxes,show_text=False) \n",
    "\n",
    "#draw rectangles also gets patches\n",
    "patches,boxes_per_page=draw_rectangles(path,boxes,show_images=False) #patches only contain the protions of the \n",
    "\n",
    "#filter thresholds function uses the 4 functions to filter the boxes to remove noise\n",
    "area_th=2 #small blocks have low area\n",
    "contour_th=2 #plain horizontal lines have low conoturs\n",
    "text_th_ocr=2 #page number boxes have have low text\n",
    "text_th_xml=3 #xml text below this chars text blocks are ignored\n",
    "\n",
    "thresholds=[text_th_ocr,contour_th,area_th,text_th_xml] #this is the thresholds list\n",
    "\n",
    "print(\"=\"*20)\n",
    "#we can filter the boxes based on 4 thresholds defined above\n",
    "selected,box_cc=filter_thresholds(thresholds,patches,boxes_text,boxes,show_text=False,show_image=False)\n",
    "\n",
    "\n",
    "\n",
    "patches,boxes_per_page=draw_rectangles(path,box_cc,show_images=False) \n",
    "#print(boxes_per_page)\n",
    "\n",
    "\n",
    "#we now have the cropped images in patches and box per page is the dictionary\n",
    "try:\n",
    "    delete_irrelevant_images(selected,all_images) #delete images that are not relevant \n",
    "except:\n",
    "    print(\"one or more of images not present !\")\n",
    "\n",
    "\n",
    "#get categories\n",
    "category_map=get_original_labels()\n",
    "\n",
    "\n",
    "#get the transformed look up tabel\n",
    "new_look_up=make_lookups(box_cc,category_map,binary=True) #binary denotes we only want proofs and theorems\n",
    "\n",
    "\n",
    "#convert these boxes into boxes to yolo\n",
    "new_look_up=boxes_to_yolo(new_look_up)\n",
    "\n",
    "#write the files to the directory\n",
    "write_file_directory(category_map,path,new_look_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(box_cc):\n",
    "    \n",
    "    #get unique page numbers in a list\n",
    "    page_coordinate={}\n",
    "    for element in box_cc:\n",
    "        if(element[0] not in page_coordinate):\n",
    "            page_coordinate[element[0]]=[element[1:]]\n",
    "        else:\n",
    "            page_coordinate[element[0]].append(element[1:])\n",
    "            \n",
    "    uniques_per_page={}\n",
    "    \n",
    "    \n",
    "    for k,v in page_coordinate.items():\n",
    "        page=k\n",
    "        values_for_that_page=v\n",
    "        \n",
    "        tags_cc={}\n",
    "        \n",
    "        for rectangles in values_for_that_page:\n",
    "            if(rectangles[1] not in tags_cc):\n",
    "                tags_cc[rectangles[1]]=[rectangles[0]]\n",
    "            else:\n",
    "                tags_cc[rectangles[1]].append(rectangles[0])\n",
    "                \n",
    "        \n",
    "        for key,element in zip(tags_cc,tags_cc.values()):\n",
    "            d=list(map(lambda x:x[0],element)) #bot left ####\n",
    "            a=list(map(lambda x:x[1],element)) #top left #\n",
    "            c=list(map(lambda x:x[2],element)) #bot rights\n",
    "            b=list(map(lambda x:x[3],element)) #top right  #####\n",
    "            \n",
    "            c=np.array(c)\n",
    "            a=np.array(a)\n",
    "            d=np.array(d)\n",
    "            b=np.array(b)\n",
    "            \n",
    "            \n",
    "            xmax, ymax = c.max(axis=0)\n",
    "            c=[xmax,ymax] ###converted c\n",
    "            \n",
    "            \n",
    "            xmin, ymin = a.min(axis=0)\n",
    "            a=[xmin,ymin] #converted a\n",
    "            \n",
    "            #for b we need to apply max min\n",
    "            \n",
    "            bmaxx, bmaxy = b.max(axis=0)\n",
    "            bminx, bminy = b.min(axis=0)\n",
    "            \n",
    "            b=[bmaxx, bminy]\n",
    "            \n",
    "            \n",
    "            #for d we need to apply min max\n",
    "            \n",
    "            dmaxx, dmaxy = d.max(axis=0)\n",
    "            dminx, dminy = d.min(axis=0)\n",
    "            \n",
    "            d=[dminx, dmaxy]\n",
    "            \n",
    "            #after the order is c,a,b,d\n",
    "            big_box=[d,a,c,b]\n",
    "            \n",
    "            tags_cc[key]=big_box\n",
    "        \n",
    "        uniques_per_page[k]=tags_cc\n",
    "    \n",
    "    final=[]\n",
    "    for page,boxes in uniques_per_page.items():\n",
    "        for label,box in boxes.items():\n",
    "            temp=[page,box,label]\n",
    "            final.append(temp)\n",
    "    return final\n",
    "\n",
    "merge_boxes(box_cc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in file directory\n",
    "\n",
    "def write_file_directory(category_map,ppath,new_look_up):\n",
    "    \n",
    "    #we need this import inside path because path is now a keyword\n",
    "    from os import path\n",
    "    \n",
    "    #make the classes.txt file\n",
    "    if(path.exists(ppath+\"/\"+\"classes.txt\")):\n",
    "        os.remove(ppath+\"/\"+\"classes.txt\")\n",
    "        \n",
    "    classes_text=open(ppath+\"/\"+\"classes.txt\",\"w+\")\n",
    "    \n",
    "    for element in category_map:\n",
    "        classes_text.write(element+\"\\n\")\n",
    "        \n",
    "    classes_text.close()\n",
    "    \n",
    "    \n",
    "    for k,v in new_look_up.items():\n",
    "        for box in v:\n",
    "            page_no=box[0]\n",
    "            values=box[1]\n",
    "            values=list(map(lambda x:str(x),values))\n",
    "            values=str(k)+\" \"+\" \".join(values)\n",
    "            \n",
    "            #open the file\n",
    "            f_no=ppath+\"/\"+\"image_\"+str(page_no)+\".txt\"\n",
    "            \n",
    "            if(path.exists(f_no)):\n",
    "                os.remove(f_no)\n",
    "                \n",
    "    #print(\"this is my new look up \",new_look_up)\n",
    "    \n",
    "    #make the other files\n",
    "    for k,v in new_look_up.items():\n",
    "        for box in v:\n",
    "            page_no=box[0]\n",
    "            values=box[1]\n",
    "            values=list(map(lambda x:str(x),values))\n",
    "            values=str(k)+\" \"+\" \".join(values)\n",
    "            \n",
    "            #open the file\n",
    "            f_no=ppath+\"/\"+\"image_\"+str(page_no)+\".txt\"\n",
    "            \n",
    "            if(path.exists(f_no)):\n",
    "                file=open(f_no,\"a+\")\n",
    "                file.write(values+\"\\n\")\n",
    "                file.close()\n",
    "            else:\n",
    "                file=open(f_no,\"w+\")\n",
    "                file.write(values+\"\\n\")\n",
    "                file.close()\n",
    "    \n",
    "    #make the\n",
    "\n",
    "write_file_directory(category_map,path,new_look_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pdf2image import convert_from_path\n",
    "from math import floor\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def get_annotaions_for_yolo(sample_pdf,xml_main,annot_xml):\n",
    "    \n",
    "    try:\n",
    "        #get the sample pdf path \n",
    "        path=sample_pdf.rsplit(\"/\",1)[0]+\"/images\"\n",
    "        #print(path)\n",
    "        \n",
    "        if(os.path.exists(path)):\n",
    "            shutil.rmtree(path, ignore_errors=True)\n",
    "        \n",
    "        #print(\"this is my sample_pdf\",sample_pdf)\n",
    "        \n",
    "        remove_pdf_links(sample_pdf)\n",
    "        #print(\"done 1\")\n",
    "        \n",
    "        #converts the pdf into images\n",
    "        all_images,resolution,skip= pdf2_image(sample_pdf,xml_main)\n",
    "        #print(skip)\n",
    "        #print(\"done 2\")\n",
    "\n",
    "        #get magnifications\n",
    "        magnifications=get_magnifications(sample_pdf,resolution,all_images)\n",
    "        #print(\"done 3\")\n",
    "        \n",
    "        #get all boxes from annot xml\n",
    "        boxes=get_all_boxes(annot_xml,magnifications,skip)\n",
    "        #print(\"done 4\")\n",
    "        \n",
    "        #we have seen 4 methods to filter these patches\n",
    "\n",
    "        #1 works on the pytesseract ocr way it takes time\n",
    "        #2 works on detecting the contours in the image \n",
    "        #3 works on the area based filtering of patches\n",
    "        #4 works on text extraction by xml\n",
    "\n",
    "\n",
    "        # but text extraction works on box coordinates not on patches\n",
    "        boxes_text=box_to_text_using_xml(xml_main,magnifications,boxes,show_text=False,skip=skip)\n",
    "        #print(\"done 5\")\n",
    "\n",
    "        #draw rectangles also gets patches\n",
    "        patches,boxes_per_page=draw_rectangles(path,boxes,show_images=False) #patches only contain the protions of the \n",
    "        #print(\"done 6\")\n",
    "        \n",
    "\n",
    "        #we can filter the boxes based on 4 thresholds defined above\n",
    "        selected,box_cc=filter_thresholds(patches,boxes_text,boxes,show_text=False,show_image=False)\n",
    "        \n",
    "        box_cc=merge_boxes(box_cc)\n",
    "\n",
    "        #selected is the text per page\n",
    "        #print(\"=\"*20)\n",
    "        #print(selected)\n",
    "        #print(\"=\"*20)\n",
    "        #print(\"done 7\")\n",
    "\n",
    "        #patches,boxes_per_page=draw_rectangles(path,box_cc,show_images=False) \n",
    "        #print(\"done 8\")\n",
    "\n",
    "        #we now have the cropped images in patches and box per page is the dictionary\n",
    "        try:\n",
    "            delete_irrelevant_images(selected,all_images,path) #delete images that are not relevant \n",
    "        except:\n",
    "            print(\"one or more of images not present !\")\n",
    "        \n",
    "        #print(\"done 9\")\n",
    "        \n",
    "\n",
    "        #get categories\n",
    "        category_map=get_original_labels()\n",
    "        \n",
    "        #print(\"=\"*20)\n",
    "        #print(box_cc) #this is the box coordinate and the label (dict)\n",
    "        #print(\"=\"*20)\n",
    "        #print(\"done 10\")\n",
    "        \n",
    "        #get the transformed look up table\n",
    "        new_look_up=make_lookups(box_cc,category_map,binary=True) #binary denotes we only want proofs and theorems\n",
    "        #print(\"done 11\")\n",
    "        \n",
    "        \n",
    "        #convert these boxes into boxes to yolo\n",
    "        new_look_up=boxes_to_yolo(new_look_up,path)\n",
    "        #new_look_up=boxes_to_pascal_voc(new_look_up,path)\n",
    "        #print(new_look_up)\n",
    "        #print(new_look_up.keys())\n",
    "        #print(\"done 12\")\n",
    "\n",
    "        #write the files to the directory\n",
    "        write_file_directory(category_map,path,new_look_up)\n",
    "        #print(\"done 13\")\n",
    "        print(\"success:\",sample_pdf)\n",
    "        return 0\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        if(not os.path.exists(xml_main)):\n",
    "            print(\"one of the files missing, please check the folder : {}\".format(xml_main))\n",
    "            \n",
    "        return 1\n",
    "    except:\n",
    "        return 2\n",
    "    \n",
    "#check /Users/mv96/tkb-pdfs/1901.09434\n",
    "\n",
    "sample_pdf='' #this is the pdf with links\n",
    "xml_main='' #this contains the page locations\n",
    "annot_xml='' #this contains annotations width\n",
    "\n",
    "\n",
    "get_annotaions_for_yolo(sample_pdf,xml_main,annot_xml)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_directory_6000=\"\" #the name of the directory containing all the 6000 pdfs\n",
    "\n",
    "import os\n",
    "arr = os.listdir(pdf_directory_6000)\n",
    "\n",
    "\n",
    "#go in each folder\n",
    "from os import walk\n",
    "\n",
    "#getting the file names of xml files and pdf's\n",
    "paths=[]\n",
    "for (dirpath, dirnames, filenames) in walk(pdf_directory_6000):\n",
    "    for sub_folder in dirnames:\n",
    "        for (dirpath, dirnames, filenames) in walk(pdf_directory_6000+\"/\"+sub_folder):\n",
    "            pdf_path=pdf_directory_6000+\"/\"+sub_folder+\"/{}.pdf\".format(sub_folder)\n",
    "            xml_main=pdf_directory_6000+\"/\"+sub_folder+\"/{}.xml\".format(sub_folder)\n",
    "            annot_xml=pdf_directory_6000+\"/\"+sub_folder+\"/{}_annot.xml\".format(sub_folder)\n",
    "            if([pdf_path,xml_main,annot_xml] not in paths):\n",
    "                paths.append([pdf_path,xml_main,annot_xml])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one by one execution\n",
    "\n",
    "def logs_write(paths,flags):\n",
    "    logs=list(map(lambda x:x[0].rsplit(\"/\",1)[0],paths))\n",
    "    logs_dict={}\n",
    "    \n",
    "    for element,label in zip(logs,flags):\n",
    "        if(label not in logs_dict):\n",
    "            logs_dict[label]=[element]\n",
    "        else:\n",
    "            logs_dict[label].append(element)\n",
    "            \n",
    "    return logs_dict\n",
    "\n",
    "\n",
    "\n",
    "flags=[]\n",
    "\n",
    "one_by_one=False; thresh=len(paths); #for all use len(paths)\n",
    "\n",
    "paths=paths[:thresh+1]\n",
    "\n",
    "if(one_by_one==True): #one by one execution will label data one at a time\n",
    "    \n",
    "    for file in tqdm(paths):\n",
    "        ret=get_annotaions_for_yolo(file[0],file[1],file[2])\n",
    "        flags.append(ret)\n",
    "        \n",
    "    logs_dict=logs_write(paths,flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-sperm",
   "metadata": {},
   "source": [
    "# multi processing the code to further optimize the speed of labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi process the code\n",
    "from joblib import Parallel, delayed  \n",
    "from tqdm import tqdm\n",
    "\n",
    "#there could be over flow of resources so one can reduce the n_jobs parameter\n",
    "res = Parallel(n_jobs=-1, verbose=10)(delayed(get_annotaions_for_yolo)(file[0],file[1],file[2])\n",
    "                             for file in tqdm(paths))\n",
    "\n",
    "\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=logs_write(paths,res)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f061faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all the folders that are therein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the images in the dataset\n",
    "pdf_directory_6000=\"\" #the name of the directory containing all the 6000 pdfs\n",
    "\n",
    "#traverse through each of the directory and print the files\n",
    "#we have 4399 folders with title images\n",
    "#we have 4161 folders that have images\n",
    "#we have 3769 folders that actually have images and text associated\n",
    "\n",
    "count=0\n",
    "selected=[]\n",
    "for element in logs[None]: #only the successful logs directory go through this\n",
    "    dir_list = os.listdir(element) \n",
    "    \n",
    "    \n",
    "    if(\"images\" in dir_list): #\n",
    "        dir_list_1=os.listdir(element+\"/\"+\"images\") \n",
    "        \n",
    "        images_list=list(filter(lambda x: x.endswith(\".png\"),dir_list_1)) #select all png\n",
    "        text_list=list(filter(lambda x: x.endswith(\".txt\"),dir_list_1)) #select all txt\n",
    "        \n",
    "        #print(images_list)\n",
    "        #print(text_list)\n",
    "        \n",
    "        for img in images_list:\n",
    "            just_name=img.split(\".\")[0]\n",
    "            \n",
    "            if(just_name+\".txt\" in text_list):\n",
    "                selected.append(element+\"/\"+\"images\"+\"/\"+img)\n",
    "                selected.append(element+\"/\"+\"images\"+\"/\"+just_name+\".txt\")\n",
    "                \n",
    "#this contains all the successful folders with images that have images and corresponding .txt\n",
    "print(len(selected))    #images and text in one big list\n",
    "\n",
    "images_list=list(filter(lambda x: x.endswith(\".png\"),selected)) #image_list\n",
    "text_list=list(filter(lambda x: x.endswith(\".txt\"),selected)) #txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example to copy and paste file on OS\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "#copyfile(\"/Users/mv96/Desktop/me_image.jpeg\", \"/Users/mv96/Desktop/urgent_things/me_image.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we wanna save everything into a new directory\n",
    "#train_directory=\"/home/mishra/tkb-images\"\n",
    "from shutil import copyfile\n",
    "import os\n",
    "\n",
    "dest=\"\" #the directory where you want to save the images\n",
    "\n",
    "if(os.path.exists(dest)):\n",
    "    print(\"path exists !!!\")\n",
    "else:\n",
    "    print(\"create a new directory of tkb images\")\n",
    "    os.mkdir(dest)\n",
    "\n",
    "\n",
    "for img,text in zip(images_list,text_list):\n",
    "\n",
    "    image_path_write=dest+\"_\".join(img.rsplit(\"/\",3)[1:])\n",
    "\n",
    "    text_path_write=dest+\"_\".join(text.rsplit(\"/\",3)[1:])\n",
    "    \n",
    "    \n",
    "    copyfile(img, image_path_write)\n",
    "    copyfile(text, text_path_write)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-summit",
   "metadata": {},
   "source": [
    " 51921 images saved in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-geometry",
   "metadata": {},
   "source": [
    "1. copy classes.txt from any of the one file to this to make sure all class labels are present \n",
    "\n",
    "2. make sure the images are easily opened in labelimg format to just be sure of the op directory\n",
    "\n",
    "3. follow yolo v4 collab notebook https://colab.research.google.com/drive/1FnjVjnwaPSnX6tZSwxBm4w13-CmnDcEt?usp=sharing and tutorial on youtube https://www.youtube.com/watch?v=mmj3nxGT2YQ&t=1143s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa120c4",
   "metadata": {},
   "source": [
    "# Class based implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48af681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from pdf2image import convert_from_path\n",
    "from math import floor\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import natsort \n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "import copy\n",
    "from itertools import compress\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_Pre_Processing:\n",
    "    \n",
    "    out_pdf=\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #default values\n",
    "        self.sample_pdf='/Users/mv96/Desktop/temp/1902.11202/1902.11202.pdf' \n",
    "        self.xml_main='/Users/mv96/Desktop/temp/1902.11202/1902.11202.xml' \n",
    "        self.annot_xml='/Users/mv96/Desktop/temp/1902.11202/1902.11202_annot.xml' \n",
    "        self.path=self.sample_pdf.rsplit(\"/\",1)[0]+\"/images\"\n",
    "        self.area_th=2 #small blocks have low area\n",
    "        self.contour_th=8 #plain horizontal lines have low contours\n",
    "        self.text_th_ocr=2 #page number boxes have have low text\n",
    "        self.text_th_xml=3\n",
    "        self.thresholds=[self.text_th_ocr,self.contour_th,self.area_th,self.text_th_xml]\n",
    "        self.pdf_directory=\"/Users/mv96/tkb_pdfs\"\n",
    "        self.flags=[]\n",
    "        \n",
    "\n",
    "    def remove_pdf_links(self,out_pdf=None):\n",
    "\n",
    "        if(out_pdf==None):\n",
    "            out_pdf=self.sample_pdf.rsplit(\".\",1)\n",
    "            out_pdf_temp=out_pdf[0]+\"_stripped_temp.\"+out_pdf[1]\n",
    "            out_pdf=out_pdf[0]+\"_stripped.\"+out_pdf[1]\n",
    "\n",
    "\n",
    "\n",
    "        #code for conversion\n",
    "        first_cmd=\" \".join([\"pdftk\", \"{}\".format(self.sample_pdf),\"output\", \"{}\".format(out_pdf_temp), \"uncompress\"])\n",
    "        second_cmd=\"LC_ALL=C sed -n '/^\\/Annots/!p' {} > {}\".format(out_pdf_temp,self.sample_pdf)\n",
    "\n",
    "        #call first command \n",
    "\n",
    "        subprocess.call(first_cmd,shell=True)\n",
    "\n",
    "        #call second command\n",
    "        ret=subprocess.call(second_cmd,shell=True)\n",
    "\n",
    "        os.remove(out_pdf_temp)\n",
    "        \n",
    "\n",
    "        \n",
    "    def pdf2_image(self):\n",
    "    \n",
    "        #get the resolution of each pdf page from xml\n",
    "        content = []\n",
    "        # Read the XML file\n",
    "        with open(self.xml_main, \"r\") as file:\n",
    "            # Read each line in the file, readlines() returns a list of lines\n",
    "            content = file.readlines()\n",
    "            # Combine the lines in the list into a string\n",
    "            content = \"\".join(content)\n",
    "            bs_content = bs(content, \"xml\")\n",
    "            #print(bs_content)\n",
    "            page_info=bs_content.find_all(\"Page\")\n",
    "            resolution=[]\n",
    "            for page in page_info:\n",
    "                height=floor(float(page.get(\"HEIGHT\")))\n",
    "                width=floor(float(page.get(\"WIDTH\")))\n",
    "                resolution.append((width,height))\n",
    "        file.close()\n",
    "\n",
    "        #print(resolution)\n",
    "\n",
    "        #convert the pdf to image using the coordinates from the xml_file\n",
    "        all_pages=[]\n",
    "\n",
    "        ff=1\n",
    "        lf=len(resolution)\n",
    "        image = convert_from_path(self.sample_pdf,first_page=ff,last_page=lf,use_pdftocairo=True,fmt=\"png\")\n",
    "\n",
    "        skip=False #default value\n",
    "\n",
    "        if(len(resolution)!=len(image)):\n",
    "            skip=True\n",
    "            resolution.pop(0)\n",
    "\n",
    "\n",
    "        #print(all_pages)\n",
    "\n",
    "        #make a new directory in pdf folder\n",
    "        self.resolution=resolution\n",
    "        self.skip=skip\n",
    "        self.all_images=image\n",
    "        \n",
    "\n",
    "        return image,resolution,skip\n",
    "    \n",
    "    def get_magnifications(self):\n",
    "    \n",
    "        try:\n",
    "            path=self.sample_pdf.rsplit(\"/\",1)[0]+\"/images\"\n",
    "            #print(path)\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass\n",
    "            #print(\"path already exists !!!!\")\n",
    "\n",
    "        #print(path)     \n",
    "        magnifications=[]\n",
    "\n",
    "        i=0\n",
    "        for image,res in zip(self.all_images,self.resolution):\n",
    "            #print (image.format, image.size, image.mode)\n",
    "            new_width=image.size[0]\n",
    "            original_width=res[0]\n",
    "            new_height=image.size[1]\n",
    "            original_height=res[1]\n",
    "            mag_width=new_width/original_width\n",
    "            mag_height=new_height/original_height\n",
    "            magnifications.append([mag_width,mag_height])\n",
    "            #image.show()\n",
    "            image.save(path+\"/\"+\"image_\"+str(i+1)+'.png', 'PNG')\n",
    "            i+=1\n",
    "        \n",
    "        self.magnifications=magnifications\n",
    "        \n",
    "\n",
    "        return magnifications\n",
    "    \n",
    "    \n",
    "    def get_all_boxes(self):\n",
    "        # Read the XML file\n",
    "        with open(self.annot_xml, \"r\") as file:\n",
    "            # Read each line in the file, readlines() returns a list of lines\n",
    "            content = file.readlines()\n",
    "            # Combine the lines in the list into a string\n",
    "            #print(content)\n",
    "            content = \"\".join(content)\n",
    "            bs_content = bs(content, \"xml\")\n",
    "\n",
    "\n",
    "            page_info=bs_content.find_all(\"ANNOTATION\")\n",
    "            quads=bs_content.find_all(\"QUADRILATERAL\")\n",
    "\n",
    "\n",
    "\n",
    "            extractions=[]\n",
    "            #filter magnifications for certain pages\n",
    "\n",
    "\n",
    "            for action_,quad in zip(page_info,quads):\n",
    "                if(action_.DEST.string!=None): #valid box\n",
    "                    page_no=int(action_.get(\"pagenum\")) #basically the page_num\n",
    "\n",
    "                    class_=action_.DEST.string #the type of the box\n",
    "\n",
    "                    #if the type of the box is some link then skip it dont extract it\n",
    "                    if(\"@\" in class_):\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    coord=[[floor(float(x.get(\"HPOS\"))),floor(float(x.get(\"VPOS\")))] for x in quad] #the coordinates\n",
    "                    if(self.skip):\n",
    "                        extractions.append([page_no-1,coord,class_]) \n",
    "                    else:\n",
    "                        extractions.append([page_no,coord,class_]) \n",
    "\n",
    "        file.close()\n",
    "\n",
    "        #print(extractions)\n",
    "        #we need to filter magnifications for each page\n",
    "        for i in range(len(self.magnifications)):\n",
    "            #print(i)\n",
    "            for k,elements in enumerate(extractions):\n",
    "                #print(elements)\n",
    "                #print(elements)\n",
    "                if(elements[0]==i+1):\n",
    "\n",
    "                    #print(extractions[k][1])\n",
    "\n",
    "                    #change the two coordinates\n",
    "                    for d in range(len(elements[1])): #for all coordinates change their pix values\n",
    "                        extractions[k][1][d][0]=floor(extractions[k][1][d][0]*self.magnifications[i][0])\n",
    "                        extractions[k][1][d][1]=floor(extractions[k][1][d][1]*self.magnifications[i][1])\n",
    "\n",
    "        \n",
    "        \n",
    "        self.boxes=extractions\n",
    "        return extractions\n",
    "    \n",
    "    def draw_rectangles(self,show_images=False):\n",
    "        \"\"\"takes the images from the image path reads them and plots a rectange on them\n",
    "        also return the patches for each detected page  \n",
    "        \"\"\"\n",
    "        #print(images_dir)\n",
    "        \n",
    "        pages=[]\n",
    "        box=[]\n",
    "        names=[]\n",
    "\n",
    "        boxes_per_page={}\n",
    "        for info in self.boxes:\n",
    "            page=info[0]\n",
    "            rect=info[1]\n",
    "            if(page not in boxes_per_page):\n",
    "                boxes_per_page[page]=[rect]\n",
    "            else:\n",
    "                boxes_per_page[page].append(rect)\n",
    "\n",
    "        #print(boxes_per_page)\n",
    "        patches={}\n",
    "\n",
    "        for k,v in boxes_per_page.items():\n",
    "            image_path=self.path+f\"/image_{k}.png\"\n",
    "            image=cv2.imread(image_path)\n",
    "\n",
    "\n",
    "            #v=[[1,2,3,4],[1,2,3,4]]\n",
    "            cropped_images=[]\n",
    "\n",
    "            #crop the images\n",
    "            for boxes in v:\n",
    "                #print(boxes)\n",
    "                top_left=boxes[1] #x1,y1\n",
    "                bottom_right=boxes[2] #x2,y2\n",
    "\n",
    "\n",
    "                #cropping images\n",
    "                cropped = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "\n",
    "\n",
    "                cropped_images.append(cropped)\n",
    "\n",
    "\n",
    "            patches[k]= cropped_images\n",
    "\n",
    "            if(show_images): #shows all boxes including filtered boxes\n",
    "                for boxes in v:\n",
    "                    (x1,y1),(x2,y2)=boxes[1],boxes[2]\n",
    "                    image=cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "                    cv2.imshow(\"test\",image)\n",
    "                    cv2.waitKey()\n",
    "        \n",
    "        self.patches=patches\n",
    "        self.boxes_per_page=boxes_per_page\n",
    "        \n",
    "        return patches,boxes_per_page\n",
    "\n",
    "    def delete_irrelevant_images(self):\n",
    "        \n",
    "        \n",
    "        for i in range(1,len(self.all_images)): #from image 1 to last\n",
    "            if(i not in self.patches.keys()):\n",
    "                os.remove(self.path+\"/\"+\"image_\"+str(i)+'.png')\n",
    "        \n",
    "            \n",
    "    def image_to_text(self,image,show_image=False,show_text=False):\n",
    "\n",
    "        # By default OpenCV stores images in BGR format and since pytesseract assumes RGB format,\n",
    "        # we need to convert from BGR to RGB format/mode:\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ocr_chars=image_to_string(img_rgb)\n",
    "\n",
    "        if(show_text):\n",
    "            print(\"tesseract values >>>>>>>\")\n",
    "            print(\"this is my length: \",len(ocr_chars))\n",
    "            print(ocr_chars)\n",
    "            print(\"tesseract values <<<<<<<\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "        if(show_image):\n",
    "            cv2.imshow(\"detection :\",numpy_arr_of_image)\n",
    "            cv2.waitKey()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        return ocr_chars\n",
    "    \n",
    "    def get_contours_of_image(self,image,show_text=False,show_image=False):\n",
    "               \n",
    "        #we need to convert the image into gray scale to get contour values\n",
    "        # Grayscale\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        gray = cv2.cvtColor(rgb_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find Canny edges\n",
    "        edged = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "        #print(\"contours: >>>>>>>\")\n",
    "        contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if(show_text):\n",
    "            print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "\n",
    "\n",
    "        if(show_image):\n",
    "            # Draw all contours\n",
    "            # Use '-1' as the 3rd parameter to draw all\n",
    "            cv2.drawContours(image, contours, -1, (0,255,0), 1)\n",
    "            cv2.imshow('Contours:'+str(len(contours)), image)\n",
    "            cv2.waitKey()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        return len(contours)\n",
    "    \n",
    "    def image_to_area(self,image,show_text=False):\n",
    "        width=image.shape[0]\n",
    "        height=image.shape[1]\n",
    "        area=(width*height)/100 #in pixel square\n",
    "\n",
    "        if(show_text):\n",
    "            print(area)\n",
    "\n",
    "        return area\n",
    "    \n",
    "    def box_to_text_using_xml(self,show_text=False,skip=False):\n",
    "        \"\"\"take a box coodinates xml file to check and adjusted magnifications\n",
    "        and return what characters are inside the box basically text version\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.xml_main,\"r\") as file:\n",
    "            content=file.readlines()\n",
    "            content = \"\".join(content)\n",
    "            bs_content = bs(content, \"xml\")\n",
    "            #print(bs_content)\n",
    "            text_blocks={}\n",
    "            page_info=bs_content.find_all(\"Page\")\n",
    "\n",
    "            if(self.skip):\n",
    "                page_info.pop(0)\n",
    "\n",
    "\n",
    "            for i,page in enumerate(page_info): #traverse through all pages\n",
    "\n",
    "                page_text=page.find_all(\"TextLine\")\n",
    "                text=[]\n",
    "                for text_bl in page_text:\n",
    "\n",
    "                    for element in text_bl:\n",
    "                        if(str(element).startswith(\"<String\")): #its a string \n",
    "                            try:\n",
    "                                content=element.get(\"CONTENT\")\n",
    "                                #print(content)\n",
    "                                h_pos=floor(float(element.get(\"HPOS\"))*self.magnifications[i][0])\n",
    "                                v_pos=floor(float(element.get(\"VPOS\"))*self.magnifications[i][1])\n",
    "                                #we can also extract the font \n",
    "\n",
    "                                text.append([content,h_pos,v_pos])\n",
    "                            except:\n",
    "                                print(element)\n",
    "                                print(i)\n",
    "                                print(self.magnifications[i][0])\n",
    "                                print(content)\n",
    "\n",
    "\n",
    "                        if(str(element).startswith(\"<SP\")):\n",
    "                            val=text.pop()\n",
    "                            val[0]+=\" \"\n",
    "                            text.append(val)\n",
    "\n",
    "                    #print(text)\n",
    "\n",
    "                text_blocks[i+1]=text\n",
    "\n",
    "            file.close()\n",
    "\n",
    "\n",
    "\n",
    "        box_text={}\n",
    "        string_cats=[]\n",
    "        for box in self.boxes: #basically the big box\n",
    "            all_chars_on_page=text_blocks[box[0]] #small boxes\n",
    "\n",
    "            #coordinates of the big box\n",
    "            top_left_bb= copy.deepcopy(box[1][1])\n",
    "            bot_right_bb=copy.deepcopy(box[1][2])\n",
    "\n",
    "\n",
    "            #print(all_chars_on_page)\n",
    "            string_cat=\"\"\n",
    "\n",
    "            for chars in all_chars_on_page:\n",
    "                if(top_left_bb[0]<=chars[1]<=bot_right_bb[0] and top_left_bb[1]<=chars[2]<=bot_right_bb[1]):\n",
    "                    string_cat+=chars[0]\n",
    "\n",
    "            string_cats.append((box[0],string_cat))\n",
    "\n",
    "        for element in string_cats:\n",
    "            if(element[0] not in box_text):\n",
    "                box_text[element[0]]=[element[1]]\n",
    "            else:\n",
    "                box_text[element[0]].append(element[1])\n",
    "        \n",
    "        self.box_text=box_text\n",
    "        return box_text\n",
    "        \n",
    "    \n",
    "    def filter_thresholds(self,show_text=False,show_image=False):\n",
    "        \n",
    "        #cleaning the mess\n",
    "        thresholds=[self.text_th_ocr,self.contour_th,self.area_th,self.text_th_xml]\n",
    "        patches=self.patches\n",
    "        boxes_text=self.box_text\n",
    "        boxes=self.boxes\n",
    "        \n",
    "        box_map_cc=[]\n",
    "        selection={}\n",
    "        for page_info in patches.keys():\n",
    "\n",
    "            verdicts=[]\n",
    "\n",
    "            for image,text_xml in zip(patches[page_info],boxes_text[page_info]):\n",
    "\n",
    "                area=self.image_to_area(image,show_text=False)\n",
    "                contours_count=self.get_contours_of_image(image,show_text=False)\n",
    "                #text_ocr=self.image_to_text(numpy_arr_of_image,show_image=False,show_text=False)\n",
    "\n",
    "                if(show_text):\n",
    "                    print(\"image area: \",area)\n",
    "                    print(\"contours count: \",contours_count)\n",
    "                    #print(\"text using ocr: and length\",(text_ocr,len(text_ocr)))\n",
    "                    print(\"text using xml: and length\",(text_xml,len(text_xml)))\n",
    "                    print(\"=======\")\n",
    "\n",
    "                if(show_image):\n",
    "                    name=\"area {}. contours {}. text {}.\".format(area,contours_count,text_xml)\n",
    "                    cv2.imshow(\"name\",image)\n",
    "                    cv2.waitKey()\n",
    "                    cv2.destroyAllWindows()\n",
    "\n",
    "                small_area= area<self.area_th\n",
    "                small_contour_count= contours_count<self.contour_th\n",
    "\n",
    "                #less_text_ocr= len(text_ocr)<text_th_ocr #using tesseract ocr\n",
    "                less_text_xml=len(text_xml)<self.text_th_xml\n",
    "\n",
    "                less_text=less_text_xml\n",
    "\n",
    "                verdict=not(small_area or small_contour_count or less_text)\n",
    "                verdicts.append(verdict)\n",
    "                box_map_cc.append(verdict)\n",
    "\n",
    "\n",
    "            selection[page_info]=verdicts\n",
    "\n",
    "\n",
    "        selection_=copy.deepcopy(selection)\n",
    "\n",
    "\n",
    "        for k,sels,box in zip(selection_.copy(),selection_.values(),boxes_text.values()):\n",
    "            new_images=list(compress(box, sels))\n",
    "\n",
    "            if(len(new_images)==0):\n",
    "                del selection[k]\n",
    "            else:\n",
    "                selection[k]=new_images\n",
    "\n",
    "\n",
    "        #this is where we will start to filter each of the images\n",
    "        box_map_cc=list(compress(boxes, box_map_cc))\n",
    "        \n",
    "        self.selected=selection\n",
    "        self.boxes=box_map_cc\n",
    "        return selection ,box_map_cc\n",
    "    \n",
    "    def get_original_labels(self):\n",
    "        \"\"\"basically assigning labesls\"\"\"\n",
    "        categories=[\"assumption\",\"claim\",\"conjecture\",\"corollary\",\"definition\",\"lemma\",\"proof\",\"proposition\",\n",
    "                    \"remark\", \"theorem\"]\n",
    "\n",
    "        category_map={}\n",
    "\n",
    "        for i,element in enumerate(categories):\n",
    "            category_map[element]=i\n",
    "        \n",
    "        self.category_map=category_map\n",
    "        return category_map\n",
    "    \n",
    "    def make_lookups(self,binary=True):\n",
    "        look_up={} #this is the orgnal_lookup table matching page vs each subcategory\n",
    "        \n",
    "\n",
    "        for block in tqdm(self.boxes):\n",
    "            page_num=block[0]\n",
    "            rectangle_coords=block[1]\n",
    "            tag=\"\".join(block[2].split(\":\")[1:])\n",
    "            tag=tag.split(\".\")[0]\n",
    "            if tag not in look_up: #if tag not in look_up add that tag\n",
    "                look_up[tag]=[[page_num,rectangle_coords]]\n",
    "            else:\n",
    "                look_up[tag].append([page_num,rectangle_coords]) #else append on the same tag\n",
    "\n",
    "        #print(look_up.keys())\n",
    "\n",
    "        for element in copy.deepcopy(look_up).keys():\n",
    "            if (element not in self.category_map):\n",
    "                del look_up[element]\n",
    "        #print(set(look_up.keys()),len(set(look_up.keys())))\n",
    "\n",
    "        #get_name(\"defination1\") #this becomes defination\n",
    "\n",
    "\n",
    "        new_look_up={}\n",
    "\n",
    "        for k,v in look_up.items():\n",
    "            name=k\n",
    "            if(self.category_map[name] not in new_look_up):\n",
    "                new_look_up[self.category_map[name]]=look_up[k]\n",
    "            else:\n",
    "                for element in look_up[k]:\n",
    "                    new_look_up[self.category_map[name]].append(element)\n",
    "\n",
    "\n",
    "        #print(new_look_up)\n",
    "        #new look ups\n",
    "        ll=copy.deepcopy(new_look_up)\n",
    "\n",
    "        #put everything that is not proof in theorem \n",
    "        if(binary==True):\n",
    "            for k,v in ll.items():\n",
    "                if(k!=self.category_map[\"theorem\"] and k!= self.category_map[\"proof\"]):\n",
    "\n",
    "                    for element in new_look_up[k]:\n",
    "                        new_look_up[self.category_map[\"theorem\"]].append(element)\n",
    "\n",
    "                    #delete\n",
    "                    del new_look_up[k]\n",
    "\n",
    "        self.new_look_up=new_look_up\n",
    "        return new_look_up\n",
    "\n",
    "\n",
    "\n",
    "    def convert_yolo(self,size, box):\n",
    "        dw = 1./size[0]\n",
    "        dh = 1./size[1]\n",
    "        x = (box[0] + box[1])/2.0\n",
    "        y = (box[2] + box[3])/2.0\n",
    "        w = box[1] - box[0]\n",
    "        h = box[3] - box[2]\n",
    "        x = x*dw\n",
    "        w = w*dw\n",
    "        y = y*dh\n",
    "        h = h*dh\n",
    "        return x,y,w,h\n",
    "\n",
    "    def boxes_to_yolo(self):\n",
    "        \n",
    "        for k,v in self.new_look_up.items():\n",
    "            for i,box in enumerate(v):\n",
    "                image_no=box[0]\n",
    "\n",
    "                #read through this image path\n",
    "                image=self.path+\"/\"+\"image_\"+str(image_no)+'.png'\n",
    "                im=Image.open(image) \n",
    "\n",
    "                w= int(im.size[0]) #the x axis of the image\n",
    "                h= int(im.size[1]) #the y axis of the image\n",
    "\n",
    "                xmin=box[1][1][0]\n",
    "                ymin=box[1][1][1]\n",
    "                xmax=box[1][2][0]\n",
    "                ymax=box[1][2][1]\n",
    "\n",
    "                #print(xmin, xmax, ymin, ymax)\n",
    "\n",
    "                b = (xmin, xmax, ymin, ymax)\n",
    "\n",
    "                x,y,w,h = self.convert_yolo((w,h), b)\n",
    "\n",
    "\n",
    "                self.new_look_up[k][i][1]=[x,y,w,h]\n",
    "        \n",
    "        return self.new_look_up\n",
    "    \n",
    "    \n",
    "    def merge_boxes(self):\n",
    "    \n",
    "        #get unique page numbers in a list\n",
    "        page_coordinate={}\n",
    "        for element in self.boxes:\n",
    "            if(element[0] not in page_coordinate):\n",
    "                page_coordinate[element[0]]=[element[1:]]\n",
    "            else:\n",
    "                page_coordinate[element[0]].append(element[1:])\n",
    "\n",
    "        uniques_per_page={}\n",
    "\n",
    "\n",
    "        for k,v in page_coordinate.items():\n",
    "            page=k\n",
    "            values_for_that_page=v\n",
    "\n",
    "            tags_cc={}\n",
    "\n",
    "            for rectangles in values_for_that_page:\n",
    "                if(rectangles[1] not in tags_cc):\n",
    "                    tags_cc[rectangles[1]]=[rectangles[0]]\n",
    "                else:\n",
    "                    tags_cc[rectangles[1]].append(rectangles[0])\n",
    "\n",
    "\n",
    "            for key,element in zip(tags_cc,tags_cc.values()):\n",
    "                d=list(map(lambda x:x[0],element)) #bot left ####\n",
    "                a=list(map(lambda x:x[1],element)) #top left #\n",
    "                c=list(map(lambda x:x[2],element)) #bot rights\n",
    "                b=list(map(lambda x:x[3],element)) #top right  #####\n",
    "\n",
    "                c=np.array(c)\n",
    "                a=np.array(a)\n",
    "                d=np.array(d)\n",
    "                b=np.array(b)\n",
    "\n",
    "\n",
    "                xmax, ymax = c.max(axis=0)\n",
    "                c=[xmax,ymax] ###converted c\n",
    "\n",
    "\n",
    "                xmin, ymin = a.min(axis=0)\n",
    "                a=[xmin,ymin] #converted a\n",
    "\n",
    "                #for b we need to apply max min\n",
    "\n",
    "                bmaxx, bmaxy = b.max(axis=0)\n",
    "                bminx, bminy = b.min(axis=0)\n",
    "\n",
    "                b=[bmaxx, bminy]\n",
    "\n",
    "\n",
    "                #for d we need to apply min max\n",
    "\n",
    "                dmaxx, dmaxy = d.max(axis=0)\n",
    "                dminx, dminy = d.min(axis=0)\n",
    "\n",
    "                d=[dminx, dmaxy]\n",
    "\n",
    "                #after the order is c,a,b,d\n",
    "                big_box=[d,a,c,b]\n",
    "\n",
    "                tags_cc[key]=big_box\n",
    "\n",
    "            uniques_per_page[k]=tags_cc\n",
    "\n",
    "        final=[]\n",
    "        for page,boxes in uniques_per_page.items():\n",
    "            for label,box in boxes.items():\n",
    "                temp=[page,box,label]\n",
    "                final.append(temp)\n",
    "                \n",
    "        self.boxes=final\n",
    "        return final\n",
    "    \n",
    "    def write_file_directory(self):\n",
    "    \n",
    "        #we need this import inside path because path is now a keyword\n",
    "        from os import path\n",
    "\n",
    "        #make the classes.txt file\n",
    "        if(path.exists(self.path+\"/\"+\"classes.txt\")):\n",
    "            os.remove(self.path+\"/\"+\"classes.txt\")\n",
    "\n",
    "        classes_text=open(self.path+\"/\"+\"classes.txt\",\"w+\")\n",
    "\n",
    "        for element in self.category_map:\n",
    "            classes_text.write(element+\"\\n\")\n",
    "\n",
    "        classes_text.close()\n",
    "\n",
    "\n",
    "        for k,v in self.new_look_up.items():\n",
    "            for box in v:\n",
    "                page_no=box[0]\n",
    "                values=box[1]\n",
    "                values=list(map(lambda x:str(x),values))\n",
    "                values=str(k)+\" \"+\" \".join(values)\n",
    "\n",
    "                #open the file\n",
    "                f_no=self.path+\"/\"+\"image_\"+str(page_no)+\".txt\"\n",
    "\n",
    "                if(path.exists(f_no)):\n",
    "                    os.remove(f_no)\n",
    "\n",
    "        #print(\"this is my new look up \",new_look_up)\n",
    "\n",
    "        #make the other files\n",
    "        for k,v in self.new_look_up.items():\n",
    "            for box in v:\n",
    "                page_no=box[0]\n",
    "                values=box[1]\n",
    "                values=list(map(lambda x:str(x),values))\n",
    "                values=str(k)+\" \"+\" \".join(values)\n",
    "\n",
    "                #open the file\n",
    "                f_no=self.path+\"/\"+\"image_\"+str(page_no)+\".txt\"\n",
    "\n",
    "                if(path.exists(f_no)):\n",
    "                    file=open(f_no,\"a+\")\n",
    "                    file.write(values+\"\\n\")\n",
    "                    file.close()\n",
    "                else:\n",
    "                    file=open(f_no,\"w+\")\n",
    "                    file.write(values+\"\\n\")\n",
    "                    file.close()\n",
    "                    \n",
    "    def get_annotaions_for_yolo(self):\n",
    "    \n",
    "        try:\n",
    "            \n",
    "            if(os.path.exists(self.path)):\n",
    "                shutil.rmtree(self.path, ignore_errors=True)\n",
    "\n",
    "            #print(\"this is my sample_pdf\",sample_pdf)\n",
    "            self.remove_pdf_links()\n",
    "            self.pdf2_image()\n",
    "            self.get_magnifications()\n",
    "            self.get_all_boxes()\n",
    "            self.draw_rectangles()\n",
    "            self.delete_irrelevant_images()\n",
    "            self.box_to_text_using_xml()\n",
    "            self.filter_thresholds()\n",
    "            self.merge_boxes() #we can disable this if we dont want to merge inputs\n",
    "            self.get_original_labels()\n",
    "            self.make_lookups()\n",
    "            self.boxes_to_yolo()\n",
    "            self.write_file_directory()\n",
    "            \n",
    "            print(\"success:\",self.sample_pdf)\n",
    "            return 0\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            if(not os.path.exists(self.xml_main)):\n",
    "                print(\"one of the files missing, please check the folder : {}\".format(self.xml_main))\n",
    "            return 1\n",
    "        except:\n",
    "            return 2\n",
    "        \n",
    "        \n",
    "    def pdfs_from_directory(self):    \n",
    "        \n",
    "        arr = os.listdir(self.pdf_directory)\n",
    "\n",
    "        #getting the file names of xml files and pdf's\n",
    "        paths=[]\n",
    "        for (dirpath, dirnames, filenames) in os.walk(self.pdf_directory):\n",
    "            for sub_folder in dirnames:\n",
    "                for (dirpath, dirnames, filenames) in os.walk(self.pdf_directory+\"/\"+sub_folder):\n",
    "                    pdf_path=self.pdf_directory+\"/\"+sub_folder+\"/{}.pdf\".format(sub_folder)\n",
    "                    xml_main=self.pdf_directory+\"/\"+sub_folder+\"/{}.xml\".format(sub_folder)\n",
    "                    annot_xml=self.pdf_directory+\"/\"+sub_folder+\"/{}_annot.xml\".format(sub_folder)\n",
    "                    if([pdf_path,xml_main,annot_xml] not in paths):\n",
    "                        paths.append([pdf_path,xml_main,annot_xml])\n",
    "                        \n",
    "        self.paths=paths\n",
    "        return paths\n",
    "        \n",
    "    def logs_write(self):\n",
    "        logs=list(map(lambda x:x[0].rsplit(\"/\",1)[0],self.paths))\n",
    "        logs_dict={}\n",
    "\n",
    "        for element,label in zip(logs,self.flags):\n",
    "            if(label not in logs_dict):\n",
    "                logs_dict[label]=[element]\n",
    "            else:\n",
    "                logs_dict[label].append(element)\n",
    "        \n",
    "        self.logs_dict=logs_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Yolo_Pre_Processing()\n",
    "test.remove_pdf_links()\n",
    "test.pdf2_image()\n",
    "test.get_magnifications()\n",
    "test.get_all_boxes()\n",
    "test.draw_rectangles()\n",
    "test.delete_irrelevant_images()\n",
    "test.box_to_text_using_xml()\n",
    "test.filter_thresholds()\n",
    "#test.merge_boxes() #we can disable this if we dont want to merge certain text lines\n",
    "test.get_original_labels()\n",
    "test.make_lookups()\n",
    "test.boxes_to_yolo()\n",
    "test.write_file_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef48ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc3aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ce35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d135d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
