{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roughviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "from math import  *\n",
    "import PyPDF2 \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml.etree as etree\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf='' #this is the pdf with links\n",
    "xml_main='' #this contains the page locations\n",
    "annot_xml='' #this contains annotations width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Extracting from XML file====================\n",
      "Total no of pages: 26\n",
      "Skip present: True\n",
      "All boxes extracted: 1290\n",
      "\n",
      "\n",
      "====================showing the first few lines of the first page to show extraction====================\n",
      "['Unifying computational entropies', [[206, 230], [191, 122], [206, 352], [191, 352]], 'Basic', 1]\n",
      "['via Kullback–Leibler divergence', [[211, 219], [196, 144], [211, 363], [196, 363]], 'Basic', 1]\n",
      "['Rohit Agrawal ∗', [[190, 83], [180, 176], [190, 259], [180, 259]], 'Basic', 1]\n",
      "['rohitagr@seas.harvard.edu', [[153, 154], [143, 193], [153, 347], [143, 347]], 'Basic', 1]\n",
      "['Yi-Hsiu Chen †', [[372, 77], [362, 176], [372, 253], [362, 253]], 'Basic', 1]\n",
      "['yhchen@seas.harvard.edu', [[338, 141], [328, 193], [338, 334], [328, 334]], 'Basic', 1]\n",
      "['Thibaut Horel ‡', [[189, 81], [179, 210], [189, 291], [179, 291]], 'Basic', 1]\n",
      "\n",
      "\n",
      "====================for each annotation comparing the text blocks that fit in====================\n",
      "Pages with annotations: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26]\n",
      "Some of the lines on the page 3 are:\n",
      "Deﬁnition 1.1 (next-block pseudoentropy, informal). Let n be a security parameter,\n",
      "and X = (X1, . . . , Xm) be a random variable distributed on strings of length poly(n).\n",
      "We say that X has next-block pseudoentropy at least k if there is a random variable\n",
      "Z = (Z1, . . . , Zm), jointly distributed with X, such that:\n",
      "1. For all i = 1, . . . , m, (X1, . . . , Xi−1, Xi) is computationally indistinguishable from\n",
      "(X1, . . . , Xi−1, Zi).\n",
      "2.i=1 H (Zi|X1, . . . , Xi−1) ≥ k.\n",
      "====================all lines in the pdf (in a dataframe)====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>page_no</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unifying computational entropies</td>\n",
       "      <td>1</td>\n",
       "      <td>[[206, 230], [191, 122], [206, 352], [191, 352]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>via Kullback–Leibler divergence</td>\n",
       "      <td>1</td>\n",
       "      <td>[[211, 219], [196, 144], [211, 363], [196, 363]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Agrawal ∗</td>\n",
       "      <td>1</td>\n",
       "      <td>[[190, 83], [180, 176], [190, 259], [180, 259]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rohitagr@seas.harvard.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>[[153, 154], [143, 193], [153, 347], [143, 347]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yi-Hsiu Chen †</td>\n",
       "      <td>1</td>\n",
       "      <td>[[372, 77], [362, 176], [372, 253], [362, 253]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>The witness hardness in relative entropy then ...</td>\n",
       "      <td>26</td>\n",
       "      <td>[[103, 425], [93, 344], [103, 769], [93, 769]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2−x is convex) and the witness hardness in δ-m...</td>\n",
       "      <td>26</td>\n",
       "      <td>[[103, 425], [93, 355], [103, 780], [93, 780]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>inequality by considering the event that the s...</td>\n",
       "      <td>26</td>\n",
       "      <td>[[104, 425], [94, 371], [104, 796], [94, 796]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>event has density at least δ).</td>\n",
       "      <td>26</td>\n",
       "      <td>[[104, 137], [94, 384], [104, 521], [94, 521]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>[[311, 11], [301, 728], [311, 739], [301, 739]]</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts page_no  \\\n",
       "0                      Unifying computational entropies       1   \n",
       "1                       via Kullback–Leibler divergence       1   \n",
       "2                                       Rohit Agrawal ∗       1   \n",
       "3                             rohitagr@seas.harvard.edu       1   \n",
       "4                                        Yi-Hsiu Chen †       1   \n",
       "...                                                 ...     ...   \n",
       "1285  The witness hardness in relative entropy then ...      26   \n",
       "1286  2−x is convex) and the witness hardness in δ-m...      26   \n",
       "1287  inequality by considering the event that the s...      26   \n",
       "1288                     event has density at least δ).      26   \n",
       "1289                                                 27      26   \n",
       "\n",
       "                                           coordinates labels  \n",
       "0     [[206, 230], [191, 122], [206, 352], [191, 352]]  Basic  \n",
       "1     [[211, 219], [196, 144], [211, 363], [196, 363]]  Basic  \n",
       "2      [[190, 83], [180, 176], [190, 259], [180, 259]]  Basic  \n",
       "3     [[153, 154], [143, 193], [153, 347], [143, 347]]  Basic  \n",
       "4      [[372, 77], [362, 176], [372, 253], [362, 253]]  Basic  \n",
       "...                                                ...    ...  \n",
       "1285    [[103, 425], [93, 344], [103, 769], [93, 769]]  Basic  \n",
       "1286    [[103, 425], [93, 355], [103, 780], [93, 780]]  Basic  \n",
       "1287    [[104, 425], [94, 371], [104, 796], [94, 796]]  Basic  \n",
       "1288    [[104, 137], [94, 384], [104, 521], [94, 521]]  Basic  \n",
       "1289   [[311, 11], [301, 728], [311, 739], [301, 739]]  Basic  \n",
       "\n",
       "[1290 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================annotated lines in the pdf (in a dataframe)====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "      <th>page_no</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deﬁnition 1.1 (next-block pseudoentropy, infor...</td>\n",
       "      <td>uri:theorem.Definition.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[92.604, 327.634], [92.604, 314.733], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and X = (X1, . . . , Xm) be a random variable ...</td>\n",
       "      <td>uri:theorem.Definition.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[92.604, 341.184], [92.604, 328.282], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We say that X has next-block pseudoentropy at ...</td>\n",
       "      <td>uri:theorem.Definition.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[92.604, 354.127], [92.604, 342.437], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z = (Z1, . . . , Zm), jointly distributed with...</td>\n",
       "      <td>uri:theorem.Definition.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[92.604, 368.282], [92.604, 355.38], [519.396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. For all i = 1, . . . , m, (X1, . . . , Xi−1...</td>\n",
       "      <td>uri:theorem.Definition.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[119.877, 389.82], [119.877, 376.918], [519.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>=Er←Ry←G 1 (r)w← G 2(r)2 − KL ∗r,y,w ( R, G 1 ...</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "      <td>[[92.604, 331.922], [92.604, 284.848], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>The witness hardness in relative entropy then ...</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "      <td>[[92.604, 354.787], [92.604, 341.885], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2−x is convex) and the witness hardness in δ-m...</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "      <td>[[92.604, 368.336], [92.604, 354.842], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>inequality by considering the event that the s...</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "      <td>[[92.604, 381.885], [92.604, 368.983], [519.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>event has density at least δ).</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "      <td>[[92.604, 395.434], [92.604, 382.533], [519.39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  \\\n",
       "0    Deﬁnition 1.1 (next-block pseudoentropy, infor...   \n",
       "1    and X = (X1, . . . , Xm) be a random variable ...   \n",
       "2    We say that X has next-block pseudoentropy at ...   \n",
       "3    Z = (Z1, . . . , Zm), jointly distributed with...   \n",
       "4    1. For all i = 1, . . . , m, (X1, . . . , Xi−1...   \n",
       "..                                                 ...   \n",
       "418  =Er←Ry←G 1 (r)w← G 2(r)2 − KL ∗r,y,w ( R, G 1 ...   \n",
       "419  The witness hardness in relative entropy then ...   \n",
       "420  2−x is convex) and the witness hardness in δ-m...   \n",
       "421  inequality by considering the event that the s...   \n",
       "422                     event has density at least δ).   \n",
       "\n",
       "                       labels  page_no  \\\n",
       "0    uri:theorem.Definition.1        3   \n",
       "1    uri:theorem.Definition.1        3   \n",
       "2    uri:theorem.Definition.1        3   \n",
       "3    uri:theorem.Definition.1        3   \n",
       "4    uri:theorem.Definition.1        3   \n",
       "..                        ...      ...   \n",
       "418              uri:proof.64       26   \n",
       "419              uri:proof.64       26   \n",
       "420              uri:proof.64       26   \n",
       "421              uri:proof.64       26   \n",
       "422              uri:proof.64       26   \n",
       "\n",
       "                                           coordinates  \n",
       "0    [[92.604, 327.634], [92.604, 314.733], [519.39...  \n",
       "1    [[92.604, 341.184], [92.604, 328.282], [519.39...  \n",
       "2    [[92.604, 354.127], [92.604, 342.437], [519.39...  \n",
       "3    [[92.604, 368.282], [92.604, 355.38], [519.396...  \n",
       "4    [[119.877, 389.82], [119.877, 376.918], [519.3...  \n",
       "..                                                 ...  \n",
       "418  [[92.604, 331.922], [92.604, 284.848], [519.39...  \n",
       "419  [[92.604, 354.787], [92.604, 341.885], [519.39...  \n",
       "420  [[92.604, 368.336], [92.604, 354.842], [519.39...  \n",
       "421  [[92.604, 381.885], [92.604, 368.983], [519.39...  \n",
       "422  [[92.604, 395.434], [92.604, 382.533], [519.39...  \n",
       "\n",
       "[423 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================in sequence dataframe====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>labels</th>\n",
       "      <th>page_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unifying computational entropies</td>\n",
       "      <td>[[206, 230], [191, 122], [206, 352], [191, 352]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>via Kullback–Leibler divergence</td>\n",
       "      <td>[[211, 219], [196, 144], [211, 363], [196, 363]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Agrawal ∗</td>\n",
       "      <td>[[190, 83], [180, 176], [190, 259], [180, 259]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rohitagr@seas.harvard.edu</td>\n",
       "      <td>[[153, 154], [143, 193], [153, 347], [143, 347]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yi-Hsiu Chen †</td>\n",
       "      <td>[[372, 77], [362, 176], [372, 253], [362, 253]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>The witness hardness in relative entropy then ...</td>\n",
       "      <td>[[103, 425], [93, 344], [103, 769], [93, 769]]</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2−x is convex) and the witness hardness in δ-m...</td>\n",
       "      <td>[[103, 425], [93, 355], [103, 780], [93, 780]]</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>inequality by considering the event that the s...</td>\n",
       "      <td>[[104, 425], [94, 371], [104, 796], [94, 796]]</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>event has density at least δ).</td>\n",
       "      <td>[[104, 137], [94, 384], [104, 521], [94, 521]]</td>\n",
       "      <td>uri:proof.64</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>27</td>\n",
       "      <td>[[311, 11], [301, 728], [311, 739], [301, 739]]</td>\n",
       "      <td>Basic</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts  \\\n",
       "0                      Unifying computational entropies   \n",
       "1                       via Kullback–Leibler divergence   \n",
       "2                                       Rohit Agrawal ∗   \n",
       "3                             rohitagr@seas.harvard.edu   \n",
       "4                                        Yi-Hsiu Chen †   \n",
       "...                                                 ...   \n",
       "1285  The witness hardness in relative entropy then ...   \n",
       "1286  2−x is convex) and the witness hardness in δ-m...   \n",
       "1287  inequality by considering the event that the s...   \n",
       "1288                     event has density at least δ).   \n",
       "1289                                                 27   \n",
       "\n",
       "                                           coordinates        labels  page_no  \n",
       "0     [[206, 230], [191, 122], [206, 352], [191, 352]]         Basic        1  \n",
       "1     [[211, 219], [196, 144], [211, 363], [196, 363]]         Basic        1  \n",
       "2      [[190, 83], [180, 176], [190, 259], [180, 259]]         Basic        1  \n",
       "3     [[153, 154], [143, 193], [153, 347], [143, 347]]         Basic        1  \n",
       "4      [[372, 77], [362, 176], [372, 253], [362, 253]]         Basic        1  \n",
       "...                                                ...           ...      ...  \n",
       "1285    [[103, 425], [93, 344], [103, 769], [93, 769]]  uri:proof.64       26  \n",
       "1286    [[103, 425], [93, 355], [103, 780], [93, 780]]  uri:proof.64       26  \n",
       "1287    [[104, 425], [94, 371], [104, 796], [94, 796]]  uri:proof.64       26  \n",
       "1288    [[104, 137], [94, 384], [104, 521], [94, 521]]  uri:proof.64       26  \n",
       "1289   [[311, 11], [301, 728], [311, 739], [301, 739]]         Basic       26  \n",
       "\n",
       "[1290 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_skip(xml_main,sample_pdf):\n",
    "    \"\"\"decides if there exists an extra page in the header defining the class labels\"\"\"\n",
    "    # creating a pdf file object  \n",
    "    pdfFileObj = open(sample_pdf, 'rb')  \n",
    "\n",
    "    # creating a pdf reader object  \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "    true_page_count=pdfReader.numPages\n",
    "\n",
    "    pdfFileObj.close() \n",
    "    \n",
    "    with open(xml_main, \"r\") as file:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # Combine the lines in the list into a string\n",
    "        #print(content)\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        file.close()\n",
    "        \n",
    "    pages=bs_content.find_all(\"Page\")\n",
    "    if(true_page_count==len(pages)):\n",
    "        return False,pages\n",
    "    else:\n",
    "        #remove the first page info\n",
    "        pages.pop(0)\n",
    "        return True,pages\n",
    "    \n",
    "    \n",
    "def get_all_boxes(xml,skip=False):\n",
    "    \"\"\"returns the annotation boxes from the file\"\"\"\n",
    "    # Read the XML file\n",
    "    with open(xml, \"r\") as file:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # Combine the lines in the list into a string\n",
    "        #print(content)\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        \n",
    "        page_info=bs_content.find_all(\"ANNOTATION\")\n",
    "        quads=bs_content.find_all(\"QUADRILATERAL\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        extractions=[]\n",
    "        #filter magnifications for certain pages\n",
    "        \n",
    "        \n",
    "        for action_,quad in zip(page_info,quads):\n",
    "            if(action_.DEST.string!=None): #valid box\n",
    "                page_no=int(action_.get(\"pagenum\")) #basically the page_num\n",
    "                \n",
    "                class_=action_.DEST.string #the type of the box\n",
    "                \n",
    "                #if the type of the box is some link then skip it and dont extract it\n",
    "                if(\"@\" in class_):\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                coord=[[float(x.get(\"HPOS\")),float(x.get(\"VPOS\"))] for x in quad] #the coordinates\n",
    "                if(skip):\n",
    "                    extractions.append([page_no-1,coord,class_]) \n",
    "                else:\n",
    "                    extractions.append([page_no,coord,class_]) \n",
    "    \n",
    "    file.close()\n",
    "                \n",
    "    return extractions\n",
    "\n",
    "def get_page_wise(pages):\n",
    "    \"\"\"extract all page_wise information as textline\"\"\"\n",
    "    page_wise_text={}\n",
    "    for i in range(len(pages)):\n",
    "        txt_lines=pages[i].find_all(\"TextLine\")\n",
    "        lines=[]\n",
    "        for line in txt_lines:\n",
    "            text=\"\"\n",
    "            \n",
    "            hpos=round(float(line.get(\"HPOS\")))\n",
    "            vpos=round(float(line.get(\"VPOS\")))\n",
    "            height=round(float(line.get(\"HEIGHT\")))\n",
    "            width=round(float(line.get(\"WIDTH\")))\n",
    "            \n",
    "            top_left=[hpos,vpos]\n",
    "            bot_right=[hpos+height,vpos+width]\n",
    "            top_right=[hpos,vpos+width]\n",
    "            bot_left=[hpos+height,width]\n",
    "            \n",
    "            coordinates=[bot_left,top_left,bot_right,top_right]\n",
    "            \n",
    "            \n",
    "            for second in line:\n",
    "                if(str(second).startswith(\"<String\")): #its a string \n",
    "                    try:\n",
    "                        content=second.get(\"CONTENT\")\n",
    "                        #print(content)\n",
    "                        #we can also extract the font \n",
    "\n",
    "                        text+=content\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                if(str(second).startswith(\"<SP\")):\n",
    "                    text+=\" \" #add a space\n",
    "\n",
    "            lines.append([text,coordinates])\n",
    "\n",
    "        page_wise_text[i+1]=lines\n",
    "        \n",
    "    return page_wise_text\n",
    "\n",
    "def box_to_text_using_xml(xml_main,boxes,show_text=False,skip=False,margin=20):\n",
    "    \"\"\"looks for the textblocks that exist in the annotations \n",
    "    finds the text inside the boxes that are annotated\n",
    "    \"\"\"\n",
    "    with open(xml_main,\"r\") as file:\n",
    "        content=file.readlines()\n",
    "        content = \"\".join(content)\n",
    "        bs_content = bs(content, \"xml\")\n",
    "        #print(bs_content)\n",
    "        text_blocks={}\n",
    "        page_info=bs_content.find_all(\"Page\") #read all the page based information\n",
    "        \n",
    "        if(skip): #compute the skipping for pdf's that have a header page explaining the category labels\n",
    "            page_info.pop(0)\n",
    "        \n",
    "        \n",
    "        for i,page in enumerate(page_info): #traverse through all pages\n",
    "            \n",
    "            \n",
    "                \n",
    "            page_text=page.find_all(\"TextLine\") #look for all textlines and \n",
    "            text=[]\n",
    "            for text_bl in page_text: #for text line in all textlines\n",
    "    \n",
    "                for element in text_bl: #for elements inside a text line\n",
    "                    if(str(element).startswith(\"<String\")): #its a string \n",
    "                        try:\n",
    "                            content=element.get(\"CONTENT\")\n",
    "                            #print(content)\n",
    "                            h_pos=floor(float(element.get(\"HPOS\")))\n",
    "                            v_pos=floor(float(element.get(\"VPOS\")))\n",
    "                            #we can also extract the font \n",
    "\n",
    "                            text.append([content,h_pos,v_pos])\n",
    "                        except:\n",
    "                            print(element)\n",
    "                            print(i)\n",
    "                            print(magnifications[i][0])\n",
    "                            print(content)\n",
    "                        \n",
    "                        \n",
    "                    if(str(element).startswith(\"<SP\")):\n",
    "                        val=text.pop()\n",
    "                        val[0]+=\" \"\n",
    "                        text.append(val)\n",
    "                        \n",
    "                #print(text)\n",
    "                \n",
    "            #now we have text containing information about all the words\n",
    "            \n",
    "            text_blocks[i+1]=text\n",
    "    \n",
    "        file.close()\n",
    "        \n",
    "        \n",
    "    #print(text_blocks) #this is actually the text words per page\n",
    "    #print(text_blocks[3])\n",
    "    \n",
    "    box_text={}\n",
    "    string_cats=[]\n",
    "    for box in boxes: #basically the big box\n",
    "        all_chars_on_page=text_blocks[box[0]] #small boxes\n",
    "        \n",
    "\n",
    "        #coordinates of the big box\n",
    "        top_left_bb= copy.deepcopy(box[1][1])\n",
    "        bot_right_bb=copy.deepcopy(box[1][2])\n",
    "\n",
    "\n",
    "        #print(all_chars_on_page)\n",
    "        string_cat=\"\"\n",
    "        \n",
    "        for chars in all_chars_on_page:\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(top_left_bb[0]-margin<=chars[1]<=bot_right_bb[0]-margin and top_left_bb[1]<=chars[2]<=bot_right_bb[1]):\n",
    "                string_cat+=chars[0]\n",
    "                    \n",
    "        string_cats.append((box[0],string_cat))\n",
    "        \n",
    "    #print(string_cats)\n",
    "\n",
    "    for element in string_cats:\n",
    "        if(element[0] not in box_text):\n",
    "            box_text[element[0]]=[element[1]]\n",
    "        else:\n",
    "            box_text[element[0]].append(element[1])\n",
    "            \n",
    "    return box_text\n",
    "\n",
    "def add_tags_to_interesting_areas(boxes,interesting_regions):\n",
    "    \"\"\"add the tags to thresholds\"\"\"\n",
    "    cnt=[] #get basically all the text lines\n",
    "    for element in interesting_regions.values():\n",
    "        for sub_ele in element:\n",
    "            cnt.append(sub_ele)\n",
    "\n",
    "\n",
    "    #merge boxes with extracted text \n",
    "    boxes_with_text=[] #add the text to the coordinates\n",
    "    for box,char in zip(boxes,cnt):\n",
    "        boxes_with_text.append(box+[char])\n",
    "    \n",
    "    def filter_numbers(val): #simply numbers dont make sense either\n",
    "        try:\n",
    "            int_number=int(val.strip())\n",
    "            return False\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    #basically not a number\n",
    "    filtered_boxes_with_text=list(filter(lambda x: filter_numbers(x[3]),boxes_with_text)) #filter everything that has the text section more than 1\n",
    "    \n",
    "    # again make interesting regions but this time it does not contains the boxes and contains tags\n",
    "    interesting_regions={}  \n",
    "    for box in filtered_boxes_with_text:\n",
    "        page=box[0]\n",
    "        if(page not in interesting_regions):\n",
    "            interesting_regions[page]=[box[1:]]\n",
    "        else:\n",
    "            interesting_regions[page].append(box[1:])\n",
    "            \n",
    "    return interesting_regions\n",
    "\n",
    "def filter_blanks(interesting_regions):\n",
    "    for k,v in interesting_regions.items():\n",
    "        interesting_regions[k]=list(filter(lambda x:len(x[2])>0,interesting_regions[k]))\n",
    "    return interesting_regions\n",
    "\n",
    "def make_data_frame_all_data(page_wise_text):\n",
    "    texts=[]\n",
    "    pages=[]\n",
    "    coordinates=[]\n",
    "    \n",
    "    for k,element in page_wise_text.items():\n",
    "        for text in element:\n",
    "            texts.append(text[0])\n",
    "            pages.append(k)\n",
    "            coordinates.append(text[1])\n",
    "            \n",
    "    temp=[texts,pages,coordinates]\n",
    "    \n",
    "    df=pd.DataFrame(temp).T\n",
    "    #add another column of labels\n",
    "    \n",
    "    \n",
    "    df.columns=[\"texts\",\"page_no\",\"coordinates\"]\n",
    "    df[\"labels\"]=\"Basic\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "#make dataframe out of the page wise text\n",
    "#and then if the entry exist in df then add another section of the label\n",
    "def make_data_frame_interesting(interesting_regions):\n",
    "    text=[]\n",
    "    tag=[]\n",
    "    pages=[]\n",
    "    coords=[]\n",
    "    \n",
    "    for k,v in interesting_regions.items():\n",
    "        for sub_element in v:\n",
    "            tag.append(sub_element[1])\n",
    "            text.append(sub_element[2])\n",
    "            pages.append(k)\n",
    "            coords.append(sub_element[0])\n",
    "    dict={'texts': text, 'labels': tag, \"page_no\" :pages, \"coordinates\" :coords} \n",
    "\n",
    "    df = pd.DataFrame(dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#traverse through each annotation in the annotations and look if the line lies under the annotation box\n",
    "def annotate_all(all_df,page_wise_text,interesting_regions,margin=14):\n",
    "\n",
    "    main_list=[]\n",
    "    for page_no in page_wise_text:\n",
    "        if(page_no not in interesting_regions):\n",
    "            for element in page_wise_text[page_no]:\n",
    "                element.append(\"Basic\")\n",
    "                element.append(page_no)\n",
    "                main_list.append(element)\n",
    "        else:\n",
    "            values= interesting_regions[page_no]\n",
    "\n",
    "            all_coordinates_annotations=list(map(lambda x: x[:3] ,values))\n",
    "            #print(all_coordinates)\n",
    "            #traverse through each line coordinates in the coordinates\n",
    "            #filter specific page\n",
    "            test=all_df[all_df[\"page_no\"]==page_no]\n",
    "\n",
    "            probable=[]\n",
    "            all_line_coordinates = test[[\"texts\", \"coordinates\"]].values.tolist()\n",
    "            for annotation_box in all_coordinates_annotations:\n",
    "                for line_to_check in all_line_coordinates:\n",
    "                    match=False\n",
    "                    #print(\"=\"*20)\n",
    "                    #print(annotation_box)\n",
    "                    #print(\"=\"*20)\n",
    "                    #print(line_to_check)\n",
    "\n",
    "                    top_left_annotation=annotation_box[0][1]\n",
    "                    bot_right_annotation=annotation_box[0][2]\n",
    "\n",
    "                    top_left_line=line_to_check[1][1]\n",
    "                    bot_right_line=line_to_check[1][2]\n",
    "\n",
    "                    #print(top_left_annotation,bot_right_annotation)\n",
    "                    #print(top_left_line,bot_right_line)\n",
    "\n",
    "                    if(top_left_annotation[0]-margin<=top_left_line[0]<=bot_right_annotation[0] and \n",
    "                       top_left_annotation[1]<=top_left_line[1]<=bot_right_annotation[1]):\n",
    "                        match=True\n",
    "                        if(match==True):\n",
    "                            #print(\"+\"*20)\n",
    "                            #print(line_to_check,annotation_box[0],annotation_box[1],page_no)\n",
    "                            probable.append([line_to_check[0],annotation_box[0],annotation_box[1],page_no])\n",
    "                            match=False\n",
    "\n",
    "            tmp=[element[0] for element in probable]\n",
    "            labels=[element[2] for element in probable]\n",
    "            #print(len(labels),len(tmp))\n",
    "\n",
    "            for element in all_line_coordinates:\n",
    "                if(element[0] in tmp):\n",
    "                    #print(\"=\"*20)\n",
    "                    ind=tmp.index(element[0])\n",
    "                    element.append(labels[ind])\n",
    "                    element.append(page_no)\n",
    "                    #print(element)\n",
    "                    main_list.append(element)\n",
    "                    #print(\"=\"*20)\n",
    "                else:\n",
    "                    element.append(\"Basic\")\n",
    "                    element.append(page_no)\n",
    "                    main_list.append(element)\n",
    "                    #print(element)\n",
    "\n",
    "    df1=pd.DataFrame(main_list,columns=[\"texts\", \"coordinates\", \"labels\", \"page_no\"])\n",
    "    return df1\n",
    "\n",
    "    \n",
    "skip,pages=compute_skip(xml_main,sample_pdf)\n",
    "boxes=get_all_boxes(annot_xml,skip=skip) #coordinates of interesting regions from annotations xml\n",
    "page_wise_text=get_page_wise(pages) #all the text present as textlines from the xml main\n",
    "interesting_regions=box_to_text_using_xml(xml_main,boxes,show_text=False,skip=skip) #gets all the text for annotation boxes\n",
    "interesting_regions=add_tags_to_interesting_areas(boxes,interesting_regions) #assign tags to interesting regions\n",
    "\n",
    "#filtering blank spaces to\n",
    "#==========================================================\n",
    "interesting_regions=filter_blanks(interesting_regions)\n",
    "#==========================================================\n",
    "\n",
    "all_df=make_data_frame_all_data(page_wise_text) #make a dataframe out of all lines\n",
    "df=make_data_frame_interesting(interesting_regions) #make a dataframe out of intersting regions\n",
    "df.to_csv(\"test.csv\") #save if necessary\n",
    "\n",
    "df1=annotate_all(all_df,page_wise_text,interesting_regions)\n",
    "\n",
    "print(\"=\"*20+\"Extracting from XML file\"+\"=\"*20)\n",
    "print(\"Total no of pages:\",len(pages))\n",
    "print(\"Skip present:\",skip)\n",
    "print(\"All boxes extracted:\",sum([len(element) for element in page_wise_text.values()]))\n",
    "print(\"\\n\")\n",
    "print(\"=\"*20+\"showing the first few lines of the first page to show extraction\"+\"=\"*20)\n",
    "for element in page_wise_text[1][:7]:\n",
    "    print(element)\n",
    "print(\"\\n\")\n",
    "print(\"=\"*20+\"for each annotation comparing the text blocks that fit in\"+\"=\"*20)\n",
    "print(\"Pages with annotations:\",list(interesting_regions.keys()))\n",
    "temp=list(interesting_regions.keys())[0]\n",
    "print(\"Some of the lines on the page {} are:\".format(temp))\n",
    "for element in interesting_regions[temp][:7]:\n",
    "    print(element[2])\n",
    "\n",
    "print(\"=\"*20+\"all lines in the pdf (in a dataframe)\"+\"=\"*20)\n",
    "display(all_df)\n",
    "\n",
    "print(\"=\"*20+\"annotated lines in the pdf (in a dataframe)\"+\"=\"*20)\n",
    "display(df)\n",
    "\n",
    "print(\"=\"*20+\"in sequence dataframe\"+\"=\"*20)\n",
    "display(df1)\n",
    "\n",
    "#df1.to_csv(\"test.csv\") #save if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>labels</th>\n",
       "      <th>page_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Fact 6 Let G be a graph and let f (v) ≥ n/g(n)...</td>\n",
       "      <td>[[81, 337], [72, 441], [81, 778], [72, 778]]</td>\n",
       "      <td>uri:theorem.Fact.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>f -factor of G, then the number of components ...</td>\n",
       "      <td>[[82, 296], [72, 453], [82, 749], [72, 749]]</td>\n",
       "      <td>uri:theorem.Fact.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Fact 8 Let S be a subset of E(G). An f -factor...</td>\n",
       "      <td>[[81, 337], [72, 256], [81, 593], [72, 593]]</td>\n",
       "      <td>uri:theorem.Fact.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>if one exists, can be computed in polynomial t...</td>\n",
       "      <td>[[81, 199], [72, 269], [81, 468], [72, 468]]</td>\n",
       "      <td>uri:theorem.Fact.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Fact 11 Let A be an alternating circuit and S ...</td>\n",
       "      <td>[[81, 337], [72, 564], [81, 901], [72, 901]]</td>\n",
       "      <td>uri:theorem.Fact.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>polynomial time algorithm that outputs a set M...</td>\n",
       "      <td>[[81, 337], [72, 576], [81, 913], [72, 913]]</td>\n",
       "      <td>uri:theorem.Fact.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Fact 12 Let H be an f -factor of G and let Q b...</td>\n",
       "      <td>[[81, 337], [72, 92], [81, 429], [72, 429]]</td>\n",
       "      <td>uri:theorem.Fact.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>If H/Q is connected and H[Q] is connected for ...</td>\n",
       "      <td>[[81, 337], [72, 104], [81, 441], [72, 441]]</td>\n",
       "      <td>uri:theorem.Fact.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>f -factor.</td>\n",
       "      <td>[[82, 34], [72, 116], [82, 150], [72, 150]]</td>\n",
       "      <td>uri:theorem.Fact.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Observation 14 Let G be an undirected graph an...</td>\n",
       "      <td>[[81, 337], [72, 579], [81, 916], [72, 916]]</td>\n",
       "      <td>uri:theorem.Observation.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>set V (G), there exists an f -factor H of G th...</td>\n",
       "      <td>[[81, 235], [72, 603], [81, 838], [72, 838]]</td>\n",
       "      <td>uri:theorem.Observation.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1 We use O∗(f (n)) to denote O(f (n) · nO(1)),...</td>\n",
       "      <td>[[87, 329], [79, 623], [87, 952], [79, 952]]</td>\n",
       "      <td>uri:theorem.Observation.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>f (n).</td>\n",
       "      <td>[[79, 19], [72, 634], [79, 653], [72, 653]]</td>\n",
       "      <td>uri:theorem.Observation.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  \\\n",
       "301  Fact 6 Let G be a graph and let f (v) ≥ n/g(n)...   \n",
       "302  f -factor of G, then the number of components ...   \n",
       "328  Fact 8 Let S be a subset of E(G). An f -factor...   \n",
       "329  if one exists, can be computed in polynomial t...   \n",
       "350  Fact 11 Let A be an alternating circuit and S ...   \n",
       "351  polynomial time algorithm that outputs a set M...   \n",
       "357  Fact 12 Let H be an f -factor of G and let Q b...   \n",
       "358  If H/Q is connected and H[Q] is connected for ...   \n",
       "359                                         f -factor.   \n",
       "389  Observation 14 Let G be an undirected graph an...   \n",
       "391  set V (G), there exists an f -factor H of G th...   \n",
       "392  1 We use O∗(f (n)) to denote O(f (n) · nO(1)),...   \n",
       "393                                             f (n).   \n",
       "\n",
       "                                      coordinates                     labels  \\\n",
       "301  [[81, 337], [72, 441], [81, 778], [72, 778]]         uri:theorem.Fact.1   \n",
       "302  [[82, 296], [72, 453], [82, 749], [72, 749]]         uri:theorem.Fact.1   \n",
       "328  [[81, 337], [72, 256], [81, 593], [72, 593]]         uri:theorem.Fact.2   \n",
       "329  [[81, 199], [72, 269], [81, 468], [72, 468]]         uri:theorem.Fact.2   \n",
       "350  [[81, 337], [72, 564], [81, 901], [72, 901]]         uri:theorem.Fact.3   \n",
       "351  [[81, 337], [72, 576], [81, 913], [72, 913]]         uri:theorem.Fact.3   \n",
       "357   [[81, 337], [72, 92], [81, 429], [72, 429]]         uri:theorem.Fact.4   \n",
       "358  [[81, 337], [72, 104], [81, 441], [72, 441]]         uri:theorem.Fact.4   \n",
       "359   [[82, 34], [72, 116], [82, 150], [72, 150]]         uri:theorem.Fact.4   \n",
       "389  [[81, 337], [72, 579], [81, 916], [72, 916]]  uri:theorem.Observation.5   \n",
       "391  [[81, 235], [72, 603], [81, 838], [72, 838]]  uri:theorem.Observation.5   \n",
       "392  [[87, 329], [79, 623], [87, 952], [79, 952]]  uri:theorem.Observation.5   \n",
       "393   [[79, 19], [72, 634], [79, 653], [72, 653]]  uri:theorem.Observation.5   \n",
       "\n",
       "     page_no  \n",
       "301        6  \n",
       "302        6  \n",
       "328        7  \n",
       "329        7  \n",
       "350        7  \n",
       "351        7  \n",
       "357        8  \n",
       "358        8  \n",
       "359        8  \n",
       "389        8  \n",
       "391        8  \n",
       "392        8  \n",
       "393        8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1[\"labels\"]!=\"Basic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_dataframe_extraction(sample_pdf,xml_main,annot_xml):\n",
    "    \n",
    "    try:\n",
    "        skip,pages=compute_skip(xml_main,sample_pdf)\n",
    "        boxes=get_all_boxes(annot_xml,skip=skip) #coordinates of interesting regions from annotations xml\n",
    "        page_wise_text=get_page_wise(pages) #all the text present as textlines from the xml main\n",
    "        interesting_regions=box_to_text_using_xml(xml_main,boxes,show_text=False,skip=skip) #gets all the text for annotation boxes\n",
    "        interesting_regions=add_tags_to_interesting_areas(boxes,interesting_regions) #assign tags to interesting regions\n",
    "        \n",
    "        #removing blank lines can help approximating these blank lines\n",
    "        #=====================\n",
    "        interesting_regions=filter_blanks(interesting_regions)\n",
    "        #=====================\n",
    "        \n",
    "        all_df=make_data_frame_all_data(page_wise_text) #make a dataframe out of all lines\n",
    "        df=make_data_frame_interesting(interesting_regions) #make a dataframe out of intersting regions\n",
    "        df1=annotate_all(all_df,page_wise_text,interesting_regions)\n",
    "        df1.to_csv(\"test.csv\")\n",
    "        return df1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        if(not os.path.exists(xml_main)):\n",
    "            print(\"one of the files missing, please check the folder : {}\".format(xml_main))\n",
    "        return 1\n",
    "    except:\n",
    "        return 2\n",
    "    \n",
    "sample_pdf='/Users/mv96/Desktop/temp/1902.11202/1902.11202.pdf' #this is the pdf with links\n",
    "xml_main='/Users/mv96/Desktop/temp/1902.11202/1902.11202.xml' #this contains the page locations\n",
    "annot_xml='/Users/mv96/Desktop/temp/1902.11202/1902.11202_annot.xml' #this contains annotations width\n",
    "\n",
    "res=nlp_dataframe_extraction(sample_pdf,xml_main,annot_xml)\n",
    "res.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_directory_6000=\"/Users/mv96/tkb_pdfs\"\n",
    "\n",
    "import os\n",
    "import functools\n",
    "arr = os.listdir(pdf_directory_6000)\n",
    "\n",
    "\n",
    "#go in each folder\n",
    "from os import walk\n",
    "\n",
    "#getting the file names of xml files and pdf's\n",
    "paths=[]\n",
    "for (dirpath, dirnames, filenames) in walk(pdf_directory_6000):\n",
    "    for sub_folder in dirnames:\n",
    "        for (dirpath, dirnames, filenames) in walk(pdf_directory_6000+\"/\"+sub_folder):\n",
    "            pdf_path=pdf_directory_6000+\"/\"+sub_folder+\"/{}.pdf\".format(sub_folder)\n",
    "            xml_main=pdf_directory_6000+\"/\"+sub_folder+\"/{}.xml\".format(sub_folder)\n",
    "            annot_xml=pdf_directory_6000+\"/\"+sub_folder+\"/{}_annot.xml\".format(sub_folder)\n",
    "            if([pdf_path,xml_main,annot_xml] not in paths):\n",
    "                paths.append([pdf_path,xml_main,annot_xml])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi process the code\n",
    "from joblib import Parallel, delayed  \n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    #there could be over flow of resources so one can reduce the n_jobs parameter\n",
    "    res = Parallel(n_jobs=4, verbose=10)(delayed(nlp_dataframe_extraction)(file[0],file[1],file[2])\n",
    "                                 for file in tqdm(paths))\n",
    "\n",
    "\n",
    "    res=list(filter(lambda x: isinstance(x,pd.DataFrame),res))\n",
    "\n",
    "    res=functools.reduce(lambda a,b : pd.concat([a,b]),res)\n",
    "    \n",
    "except:\n",
    "    print(\"couldn't run multiprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential execution\n",
    "res=[]\n",
    "for file in tqdm(paths):\n",
    "    df=nlp_dataframe_extraction(file[0],file[1],file[2])\n",
    "    res.append(df)\n",
    "    \n",
    "res=list(filter(lambda x: isinstance(x,pd.DataFrame),res))\n",
    "\n",
    "res=functools.reduce(lambda a,b : pd.concat([a,b]),res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"finalv2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mv96/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"finalv2.csv\")\n",
    "df=df.drop(columns=[\"Unnamed: 0\"])\n",
    "df=df.dropna(subset=['labels'])\n",
    "\n",
    "def round_labels(val):\n",
    "    \n",
    "    if(\"theorem\" in val):\n",
    "        return \"Theorem\"\n",
    "    elif (\"proof\" in val):\n",
    "        return \"Proof\"\n",
    "    else:\n",
    "        return \"Basic\"\n",
    "    \n",
    "df[\"labels\"]=df[\"labels\"].apply(round_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5281411, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic      3199559\n",
       "Proof      1582665\n",
       "Theorem     499187\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic      2349559\n",
       "Proof      1077553\n",
       "Theorem     354985\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates(subset=[\"texts\"])\n",
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3782097, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "\n",
       "<div id=\"nmigmzjrck\"></div>\n",
       "\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "require.config({paths: {roughViz: \"https://unpkg.com/rough-viz@1.0.5/dist/roughviz.min\"}});\n",
       "require([\"roughViz\"], function(roughViz) {\n",
       "\n",
       "new roughViz.Bar(\n",
       "  {\n",
       "    element: \"#\".concat(\"nmigmzjrck\"),\n",
       "    data: {\n",
       "      labels: ['Basic', 'Proof', 'Theorem'],\n",
       "      values: [2349559, 1077553, 354985]\n",
       "    },\n",
       "\taxisFontSize: \"1.5rem\",\n",
       "\taxisRoughness: 0.7,\n",
       "\taxisStrokeWidth: 0.7,\n",
       "\tbowing: 0,\n",
       "\tcolor: \"skyblue\",\n",
       "\tfillStyle: \"cross-hatch\",\n",
       "\tfillWeight: 0,\n",
       "\tfont: 0,\n",
       "\thighlight: \"gray\",\n",
       "\tinnerStrokeWidth: 0,\n",
       "\tlabelFontSize: \"2rem\",\n",
       "\tpadding: 0.1,\n",
       "\troughness: 2.3,\n",
       "\tsimplification: 0.2,\n",
       "\tstroke: \"black\",\n",
       "\tstrokeWidth: 1,\n",
       "\ttitle: \"\",\n",
       "\ttitleFontSize: \"3rem\",\n",
       "\ttooltipFontSize: \"3rem\",\n",
       "\txLabel: \"\",\n",
       "\tyLabel: \"\",\n",
       "\theight: 400,\n",
       "\twidth: 700,\n",
       "\tinteractive: true\n",
       "  }\n",
       ");\n",
       "\tvar text = document.querySelectorAll(\".xAxisnmigmzjrck .tick text\");\n",
       "\tvar i;\n",
       "\tfor (i = 0; i < text.length; i++) {\n",
       "\t\ttext[i].setAttribute(\"transform\", \"rotate(0)\");\n",
       "\t\ttext[i].style.textAnchor=\"middle\";\n",
       "\t}\n",
       "\tdocument.getElementById(\"nmigmzjrck\").style.height = \"380px\";\n",
       "\tdocument.querySelector(\"#nmigmzjrck svg\").style.height = \"380px\";\n",
       "});\n",
       "</script>\n",
       "\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories=list(df[\"labels\"].value_counts().index)\n",
    "vals=list(df[\"labels\"].value_counts())\n",
    "import roughviz\n",
    "import pandas as pd \n",
    "d = {'labels': categories, 'values': vals}\n",
    "df_ = pd.DataFrame(data=d)\n",
    "roughviz.bar(df_[\"labels\"], df_[\"values\"], axisRoughness = 0.7, axisStrokeWidth = 0.7, roughness=2.3, highlight=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "\n",
       "<div id=\"guoujblhgn\"></div>\n",
       "\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "require.config({paths: {roughViz: \"https://unpkg.com/rough-viz@1.0.5/dist/roughviz.min\"}});\n",
       "require([\"roughViz\"], function(roughViz) {\n",
       "\n",
       "new roughViz.Pie(\n",
       "  {\n",
       "    element: \"#\".concat(\"guoujblhgn\"),\n",
       "    data: {\n",
       "      labels: ['Basic', 'Proof', 'Theorem'],\n",
       "      values: [2349559, 1077553, 354985]\n",
       "    },\n",
       "\tbowing: 0,\n",
       "\tfillStyle: \"cross-hatch\",\n",
       "\tfillWeight: 0,\n",
       "\tfont: 0,\n",
       "\thighlight: \"gray\",\n",
       "\tinnerStrokeWidth: 0,\n",
       "\tmargin: {top: 50, right: 20, bottom: 70, left: 100},\n",
       "\troughness: 2.3,\n",
       "\tsimplification: 0.2,\n",
       "\tstrokeWidth: 1,\n",
       "\ttitle: \"\",\n",
       "\ttitleFontSize: \"3rem\",\n",
       "\ttooltipFontSize: \"3rem\",\n",
       "\tinteractive: true\n",
       "  }\n",
       ");\n",
       "\tvar text = document.querySelectorAll(\".xAxisguoujblhgn .tick text\");\n",
       "\tvar i;\n",
       "\tfor (i = 0; i < text.length; i++) {\n",
       "\t\ttext[i].setAttribute(\"transform\", \"rotate(0)\");\n",
       "\t\ttext[i].style.textAnchor=\"middle\";\n",
       "\t}\n",
       "\tdocument.getElementById(\"guoujblhgn\").style.height = \"380px\";\n",
       "\tdocument.querySelector(\"#guoujblhgn svg\").style.height = \"380px\";\n",
       "});\n",
       "</script>\n",
       "\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roughviz.pie(df_[\"labels\"], df_[\"values\"], axisRoughness = 0.7, axisStrokeWidth = 0.7, roughness=2.3, highlight=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the dataset by undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3782097, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle the rows\n",
    "df=df.sample(frac=1,random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle all the rows startified sample\n",
    "stratified=True\n",
    "def stratified_sample_df(df, col, n_samples):\n",
    "        n = min(n_samples, df[col].value_counts().min())\n",
    "        df_ = df.groupby(col).apply(lambda x: x.sample(n))\n",
    "        df_.index = df_.index.droplevel(0)\n",
    "        return df_\n",
    "\n",
    "if(stratified==True):\n",
    "    new=stratified_sample_df(df,\"labels\",354985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.to_csv(\"for_transformers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "\n",
       "<div id=\"chbwgwofyi\"></div>\n",
       "\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "require.config({paths: {roughViz: \"https://unpkg.com/rough-viz@1.0.5/dist/roughviz.min\"}});\n",
       "require([\"roughViz\"], function(roughViz) {\n",
       "\n",
       "new roughViz.Bar(\n",
       "  {\n",
       "    element: \"#\".concat(\"chbwgwofyi\"),\n",
       "    data: {\n",
       "      labels: ['Theorem', 'Basic', 'Proof'],\n",
       "      values: [354985, 354985, 354985]\n",
       "    },\n",
       "\taxisFontSize: \"1.5rem\",\n",
       "\taxisRoughness: 0.7,\n",
       "\taxisStrokeWidth: 0.7,\n",
       "\tbowing: 0,\n",
       "\tcolor: \"skyblue\",\n",
       "\tfillStyle: \"cross-hatch\",\n",
       "\tfillWeight: 0,\n",
       "\tfont: 0,\n",
       "\thighlight: \"gray\",\n",
       "\tinnerStrokeWidth: 0,\n",
       "\tlabelFontSize: \"2rem\",\n",
       "\tpadding: 0.1,\n",
       "\troughness: 2.3,\n",
       "\tsimplification: 0.2,\n",
       "\tstroke: \"black\",\n",
       "\tstrokeWidth: 1,\n",
       "\ttitle: \"\",\n",
       "\ttitleFontSize: \"3rem\",\n",
       "\ttooltipFontSize: \"3rem\",\n",
       "\txLabel: \"\",\n",
       "\tyLabel: \"\",\n",
       "\theight: 400,\n",
       "\twidth: 700,\n",
       "\tinteractive: true\n",
       "  }\n",
       ");\n",
       "\tvar text = document.querySelectorAll(\".xAxischbwgwofyi .tick text\");\n",
       "\tvar i;\n",
       "\tfor (i = 0; i < text.length; i++) {\n",
       "\t\ttext[i].setAttribute(\"transform\", \"rotate(0)\");\n",
       "\t\ttext[i].style.textAnchor=\"middle\";\n",
       "\t}\n",
       "\tdocument.getElementById(\"chbwgwofyi\").style.height = \"380px\";\n",
       "\tdocument.querySelector(\"#chbwgwofyi svg\").style.height = \"380px\";\n",
       "});\n",
       "</script>\n",
       "\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_of_occurances=list(new[\"labels\"].value_counts().values)\n",
    "labels=list(new[\"labels\"].value_counts().index)\n",
    "\n",
    "d = {'labels': labels, 'values': counts_of_occurances}\n",
    "df_ = pd.DataFrame(data=d)\n",
    "roughviz.bar(df_[\"labels\"], df_[\"values\"], axisRoughness = 0.7, axisStrokeWidth = 0.7, roughness=2.3, highlight=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "\n",
       "<div id=\"wmiuvdihnx\"></div>\n",
       "\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "require.config({paths: {roughViz: \"https://unpkg.com/rough-viz@1.0.5/dist/roughviz.min\"}});\n",
       "require([\"roughViz\"], function(roughViz) {\n",
       "\n",
       "new roughViz.Pie(\n",
       "  {\n",
       "    element: \"#\".concat(\"wmiuvdihnx\"),\n",
       "    data: {\n",
       "      labels: ['Theorem', 'Basic', 'Proof'],\n",
       "      values: [354985, 354985, 354985]\n",
       "    },\n",
       "\tbowing: 0,\n",
       "\tfillStyle: \"cross-hatch\",\n",
       "\tfillWeight: 0,\n",
       "\tfont: 0,\n",
       "\thighlight: \"gray\",\n",
       "\tinnerStrokeWidth: 0,\n",
       "\tmargin: {top: 50, right: 20, bottom: 70, left: 100},\n",
       "\troughness: 2.3,\n",
       "\tsimplification: 0.2,\n",
       "\tstrokeWidth: 1,\n",
       "\ttitle: \"\",\n",
       "\ttitleFontSize: \"3rem\",\n",
       "\ttooltipFontSize: \"3rem\",\n",
       "\tinteractive: true\n",
       "  }\n",
       ");\n",
       "\tvar text = document.querySelectorAll(\".xAxiswmiuvdihnx .tick text\");\n",
       "\tvar i;\n",
       "\tfor (i = 0; i < text.length; i++) {\n",
       "\t\ttext[i].setAttribute(\"transform\", \"rotate(0)\");\n",
       "\t\ttext[i].style.textAnchor=\"middle\";\n",
       "\t}\n",
       "\tdocument.getElementById(\"wmiuvdihnx\").style.height = \"380px\";\n",
       "\tdocument.querySelector(\"#wmiuvdihnx svg\").style.height = \"380px\";\n",
       "});\n",
       "</script>\n",
       "\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roughviz.pie(df_[\"labels\"], df_[\"values\"], axisRoughness = 0.7, axisStrokeWidth = 0.7, roughness=2.3, highlight=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you dont want to use full data then  that to happen\n",
    "new=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3782097, 4)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== train data (80%)====================\n",
      "(3025677, 4)\n",
      "==================== test data (20%)====================\n",
      "(756420, 4)\n"
     ]
    }
   ],
   "source": [
    "#train test split and random splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create training and testing data (80% train and 20% test)\n",
    "data_train, data_test = train_test_split(new,test_size=0.2,random_state=42,stratify=new[\"labels\"])#test size here relates to second var i.e test\n",
    "\n",
    "print(\"=\"*20+\" train data (80%)\"+\"=\"*20)\n",
    "print (data_train.shape)\n",
    "print(\"=\"*20+\" test data (20%)\"+\"=\"*20)\n",
    "print (data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add label encoding to the data \n",
    "x_train , y_train = data_train[\"texts\"],data_train[\"labels\"]\n",
    "x_test , y_test = data_test[\"texts\"],data_test[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes obtained\n",
      "['Basic' 'Proof' 'Theorem']\n"
     ]
    }
   ],
   "source": [
    "#### label encoding my y of train and test data \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "print(\"The classes obtained\")\n",
    "print(le.classes_)\n",
    "\n",
    "y_train=le.transform(y_train)\n",
    "y_test=le.transform(y_test)\n",
    "\n",
    "x_train=x_train.to_list()\n",
    "x_test=x_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3025677,) (3025677,) (756420,) (756420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(x_train,columns=[\"text\"])\n",
    "y_train=pd.DataFrame(y_train,columns=[\"labels\"])\n",
    "a=pd.concat([x_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0=a[a[\"labels\"]==0]\n",
    "a1=a[a[\"labels\"]==1]\n",
    "a2=a[a[\"labels\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.concat([a0.iloc[:1000000],a1,a2]) #select only first 10000000 for memory issues on colab\n",
    "x_train=temp[\"text\"]\n",
    "y_train=temp[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2146030,)\n",
      "(2146030,)\n",
      "(756420,)\n",
      "(756420,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
